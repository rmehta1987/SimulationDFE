/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.
  warnings.warn(
The device is: cuda
Creating embedding network
Finished creating embedding network
Setting up posteriors
True data shape (should be the same as the sample size): 111709 111709
Starting to Train
Running 200 simulations.:   0%|          | 0/200 [00:00<?, ?it/s]Running 200 simulations.:   2%|▎         | 5/200 [00:00<00:04, 47.57it/s]Running 200 simulations.:   5%|▌         | 10/200 [00:00<00:07, 24.69it/s]Running 200 simulations.:   7%|▋         | 14/200 [00:00<00:07, 24.05it/s]Running 200 simulations.:   9%|▉         | 18/200 [00:00<00:06, 27.87it/s]Running 200 simulations.:  11%|█         | 22/200 [00:00<00:07, 23.47it/s]Running 200 simulations.:  14%|█▎        | 27/200 [00:01<00:06, 27.49it/s]Running 200 simulations.:  16%|█▌        | 31/200 [00:01<00:06, 26.62it/s]Running 200 simulations.:  18%|█▊        | 37/200 [00:01<00:04, 33.35it/s]Running 200 simulations.:  20%|██        | 41/200 [00:01<00:04, 33.82it/s]Running 200 simulations.:  23%|██▎       | 46/200 [00:01<00:04, 35.93it/s]Running 200 simulations.:  25%|██▌       | 50/200 [00:01<00:04, 36.17it/s]Running 200 simulations.:  28%|██▊       | 56/200 [00:01<00:03, 36.26it/s]Running 200 simulations.:  30%|███       | 60/200 [00:01<00:04, 32.98it/s]Running 200 simulations.:  35%|███▌      | 70/200 [00:02<00:02, 46.28it/s]Running 200 simulations.:  38%|███▊      | 76/200 [00:02<00:02, 49.54it/s]Running 200 simulations.:  41%|████      | 82/200 [00:02<00:03, 38.27it/s]Running 200 simulations.:  44%|████▎     | 87/200 [00:02<00:03, 37.07it/s]Running 200 simulations.:  46%|████▌     | 92/200 [00:02<00:03, 33.10it/s]Running 200 simulations.:  48%|████▊     | 96/200 [00:02<00:03, 31.71it/s]Running 200 simulations.:  54%|█████▍    | 108/200 [00:02<00:01, 50.34it/s]Running 200 simulations.:  60%|██████    | 120/200 [00:03<00:01, 60.45it/s]Running 200 simulations.:  64%|██████▎   | 127/200 [00:03<00:01, 59.74it/s]Running 200 simulations.:  67%|██████▋   | 134/200 [00:03<00:01, 36.91it/s]Running 200 simulations.:  70%|███████   | 140/200 [00:03<00:01, 38.96it/s]Running 200 simulations.:  74%|███████▍  | 148/200 [00:03<00:01, 46.59it/s]Running 200 simulations.:  77%|███████▋  | 154/200 [00:03<00:00, 46.59it/s]Running 200 simulations.:  81%|████████  | 162/200 [00:04<00:00, 52.69it/s]Running 200 simulations.:  86%|████████▌ | 172/200 [00:04<00:00, 59.72it/s]Running 200 simulations.:  90%|████████▉ | 179/200 [00:04<00:00, 42.51it/s]Running 200 simulations.:  92%|█████████▎| 185/200 [00:04<00:00, 38.60it/s]Running 200 simulations.:  95%|█████████▌| 190/200 [00:04<00:00, 35.87it/s]Running 200 simulations.: 100%|██████████| 200/200 [00:05<00:00, 43.29it/s]Running 200 simulations.: 100%|██████████| 200/200 [00:05<00:00, 39.54it/s]
/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/sbi/utils/user_input_checks.py:711: UserWarning: Data x has device 'cuda:0'.Moving x to the data_device 'cpu'.Training will proceed on device 'cuda:0'.
  warnings.warn(
/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/sbi/utils/user_input_checks.py:435: UserWarning: Mismatch between the device of the data fed to the embedding_net and the device of the embedding_net's weights. Fed data has device 'cpu' vs embedding_net weights have device 'cuda:0'. Automatically switching the embedding_net's device to 'cpu', which could otherwise be done manually using the line `embedding_net.to('cpu')`.
  warnings.warn(
/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.
  warnings.warn(
/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/pyro/nn/auto_reg_nn.py:179: UserWarning: ConditionalAutoRegressiveNN input_dim = 1. Consider using an affine transformation instead.
  warnings.warn(
Inferring posterior for round 0

 Training neural network. Epochs trained: 1 Training neural network. Epochs trained: 2 Training neural network. Epochs trained: 3 Training neural network. Epochs trained: 4 Training neural network. Epochs trained: 5 Training neural network. Epochs trained: 6 Training neural network. Epochs trained: 7 Training neural network. Epochs trained: 8 Training neural network. Epochs trained: 9 Training neural network. Epochs trained: 10 Training neural network. Epochs trained: 11 Training neural network. Epochs trained: 12 Training neural network. Epochs trained: 13 Training neural network. Epochs trained: 14 Training neural network. Epochs trained: 15 Training neural network. Epochs trained: 16 Training neural network. Epochs trained: 17 Training neural network. Epochs trained: 18 Training neural network. Epochs trained: 19 Training neural network. Epochs trained: 20 Training neural network. Epochs trained: 21 Training neural network. Epochs trained: 22 Training neural network. Epochs trained: 23 Training neural network. Epochs trained: 24 Training neural network. Epochs trained: 25 Training neural network. Epochs trained: 26 Training neural network. Epochs trained: 27 Training neural network. Epochs trained: 28 Training neural network. Epochs trained: 29 Training neural network. Epochs trained: 30 Training neural network. Epochs trained: 31 Training neural network. Epochs trained: 32 Training neural network. Epochs trained: 33 Training neural network. Epochs trained: 34 Training neural network. Epochs trained: 35 Neural network successfully converged after 35 epochs.
 ****************************************** Building Posterior for round 0 ******************************************.

Training to emperical observation
  0%|          | 0/500 [00:00<?, ?it/s]Warmup phase, this may take a few seconds...:   0%|          | 0/500 [00:00<?, ?it/s]Loss: -72.42Std: 1.0:   0%|          | 0/500 [00:02<?, ?it/s]                        Loss: -72.42Std: 1.0:   0%|          | 1/500 [00:02<21:48,  2.62s/it]Loss: -72.44Std: 0.93:   0%|          | 1/500 [00:02<21:48,  2.62s/it]Loss: -72.42Std: 0.89:   0%|          | 1/500 [00:02<21:48,  2.62s/it]Loss: -72.43Std: 0.84:   0%|          | 1/500 [00:02<21:48,  2.62s/it]Loss: -72.43Std: 0.84:   1%|          | 4/500 [00:02<04:23,  1.88it/s]Loss: -72.44Std: 0.79:   1%|          | 4/500 [00:02<04:23,  1.88it/s]Loss: -72.45Std: 0.73:   1%|          | 4/500 [00:02<04:23,  1.88it/s]Loss: -72.46Std: 0.69:   1%|          | 4/500 [00:02<04:23,  1.88it/s]Loss: -72.46Std: 0.69:   1%|▏         | 7/500 [00:02<02:12,  3.72it/s]Loss: -72.46Std: 0.65:   1%|▏         | 7/500 [00:02<02:12,  3.72it/s]Loss: -72.45Std: 0.62:   1%|▏         | 7/500 [00:02<02:12,  3.72it/s]Loss: -72.42Std: 0.62:   1%|▏         | 7/500 [00:03<02:12,  3.72it/s]Loss: -72.42Std: 0.62:   2%|▏         | 10/500 [00:03<01:23,  5.85it/s]Loss: -72.38Std: 0.62:   2%|▏         | 10/500 [00:03<01:23,  5.85it/s]Loss: -72.38Std: 0.6:   2%|▏         | 10/500 [00:03<01:23,  5.85it/s] Loss: -72.39Std: 0.55:   2%|▏         | 10/500 [00:03<01:23,  5.85it/s]Loss: -72.39Std: 0.55:   3%|▎         | 13/500 [00:03<00:59,  8.21it/s]Loss: -72.4Std: 0.51:   3%|▎         | 13/500 [00:03<00:59,  8.21it/s] Loss: -72.4Std: 0.49:   3%|▎         | 13/500 [00:03<00:59,  8.21it/s]Loss: -72.35Std: 0.51:   3%|▎         | 13/500 [00:03<00:59,  8.21it/s]Loss: -72.35Std: 0.51:   3%|▎         | 16/500 [00:03<00:45, 10.65it/s]Loss: -72.36Std: 0.48:   3%|▎         | 16/500 [00:03<00:45, 10.65it/s]Loss: -72.35Std: 0.46:   3%|▎         | 16/500 [00:03<00:45, 10.65it/s]Loss: -72.33Std: 0.46:   3%|▎         | 16/500 [00:03<00:45, 10.65it/s]Loss: -72.33Std: 0.46:   4%|▍         | 19/500 [00:03<00:36, 13.02it/s]Loss: -72.3Std: 0.46:   4%|▍         | 19/500 [00:03<00:36, 13.02it/s] Loss: -72.3Std: 0.44:   4%|▍         | 19/500 [00:03<00:36, 13.02it/s]Loss: -72.26Std: 0.45:   4%|▍         | 19/500 [00:03<00:36, 13.02it/s]Loss: -72.26Std: 0.45:   4%|▍         | 22/500 [00:03<00:31, 15.20it/s]Loss: -72.26Std: 0.43:   4%|▍         | 22/500 [00:03<00:31, 15.20it/s]Loss: -72.24Std: 0.43:   4%|▍         | 22/500 [00:03<00:31, 15.20it/s]Loss: -72.24Std: 0.41:   4%|▍         | 22/500 [00:03<00:31, 15.20it/s]Loss: -72.24Std: 0.41:   5%|▌         | 25/500 [00:03<00:27, 17.09it/s]Loss: -72.23Std: 0.4:   5%|▌         | 25/500 [00:03<00:27, 17.09it/s] Loss: -72.22Std: 0.38:   5%|▌         | 25/500 [00:03<00:27, 17.09it/s]Loss: -72.23Std: 0.35:   5%|▌         | 25/500 [00:03<00:27, 17.09it/s]Loss: -72.23Std: 0.35:   6%|▌         | 28/500 [00:03<00:25, 18.64it/s]Loss: -72.21Std: 0.35:   6%|▌         | 28/500 [00:03<00:25, 18.64it/s]Loss: -72.26Std: 0.28:   6%|▌         | 28/500 [00:03<00:25, 18.64it/s]Loss: -72.3Std: 0.23:   6%|▌         | 28/500 [00:03<00:25, 18.64it/s] Loss: -72.3Std: 0.23:   6%|▌         | 31/500 [00:03<00:23, 19.87it/s]Loss: -72.31Std: 0.21:   6%|▌         | 31/500 [00:03<00:23, 19.87it/s]Loss: -72.27Std: 0.24:   6%|▌         | 31/500 [00:03<00:23, 19.87it/s]Loss: -72.27Std: 0.23:   6%|▌         | 31/500 [00:04<00:23, 19.87it/s]Loss: -72.27Std: 0.23:   7%|▋         | 34/500 [00:04<00:22, 20.82it/s]Loss: -72.28Std: 0.2:   7%|▋         | 34/500 [00:04<00:22, 20.82it/s] Loss: -72.28Std: 0.19:   7%|▋         | 34/500 [00:04<00:22, 20.82it/s]Loss: -72.28Std: 0.18:   7%|▋         | 34/500 [00:04<00:22, 20.82it/s]Loss: -72.28Std: 0.18:   7%|▋         | 37/500 [00:04<00:21, 21.52it/s]Loss: -72.27Std: 0.18:   7%|▋         | 37/500 [00:04<00:21, 21.52it/s]Loss: -72.3Std: 0.15:   7%|▋         | 37/500 [00:04<00:21, 21.52it/s] Loss: -72.27Std: 0.17:   7%|▋         | 37/500 [00:04<00:21, 21.52it/s]Loss: -72.27Std: 0.17:   8%|▊         | 40/500 [00:04<00:20, 22.04it/s]Loss: -72.27Std: 0.16:   8%|▊         | 40/500 [00:04<00:20, 22.04it/s]Loss: -72.26Std: 0.16:   8%|▊         | 40/500 [00:04<00:20, 22.04it/s]Loss: -72.28Std: 0.13:   8%|▊         | 40/500 [00:04<00:20, 22.04it/s]Loss: -72.28Std: 0.13:   9%|▊         | 43/500 [00:04<00:20, 22.41it/s]Loss: -72.3Std: 0.1:   9%|▊         | 43/500 [00:04<00:20, 22.41it/s]  Loss: -72.29Std: 0.11:   9%|▊         | 43/500 [00:04<00:20, 22.41it/s]Loss: -72.27Std: 0.12:   9%|▊         | 43/500 [00:04<00:20, 22.41it/s]Loss: -72.27Std: 0.12:   9%|▉         | 46/500 [00:04<00:20, 22.69it/s]Loss: -72.26Std: 0.13:   9%|▉         | 46/500 [00:04<00:20, 22.69it/s]Loss: -72.24Std: 0.14:   9%|▉         | 46/500 [00:04<00:20, 22.69it/s]Loss: -72.26Std: 0.11:   9%|▉         | 46/500 [00:04<00:20, 22.69it/s]Loss: -72.26Std: 0.11:  10%|▉         | 49/500 [00:04<00:19, 22.88it/s]Loss: -72.25Std: 0.11:  10%|▉         | 49/500 [00:04<00:19, 22.88it/s]Loss: -72.24Std: 0.12:  10%|▉         | 49/500 [00:04<00:19, 22.88it/s]Loss: -72.25Std: 0.1:  10%|▉         | 49/500 [00:04<00:19, 22.88it/s] Loss: -72.25Std: 0.1:  10%|█         | 52/500 [00:04<00:19, 22.90it/s]Loss: -72.29Std: 0.06:  10%|█         | 52/500 [00:04<00:19, 22.90it/s]Loss: -72.28Std: 0.07:  10%|█         | 52/500 [00:04<00:19, 22.90it/s]Loss: -72.27Std: 0.08:  10%|█         | 52/500 [00:04<00:19, 22.90it/s]Loss: -72.27Std: 0.08:  11%|█         | 55/500 [00:04<00:19, 23.03it/s]Loss: -72.31Std: 0.03:  11%|█         | 55/500 [00:04<00:19, 23.03it/s]Loss: -72.31Std: 0.03:  11%|█         | 55/500 [00:05<00:19, 23.03it/s]Loss: -72.33Std: 0.01:  11%|█         | 55/500 [00:05<00:19, 23.03it/s]Loss: -72.33Std: 0.01:  12%|█▏        | 58/500 [00:05<00:19, 23.12it/s]Loss: -72.33Std: 0.01:  12%|█▏        | 58/500 [00:05<00:19, 23.12it/s]Loss: -72.38Std: 0.05:  12%|█▏        | 58/500 [00:05<00:19, 23.12it/s]Loss: -72.39Std: 0.05:  12%|█▏        | 58/500 [00:05<00:19, 23.12it/s]Loss: -72.39Std: 0.05:  12%|█▏        | 61/500 [00:05<00:18, 23.17it/s]Loss: -72.42Std: 0.01:  12%|█▏        | 61/500 [00:05<00:18, 23.17it/s]Loss: -72.43Std: 0.0:  12%|█▏        | 61/500 [00:05<00:18, 23.17it/s] Loss: -72.43Std: 0.0:  12%|█▏        | 61/500 [00:05<00:18, 23.17it/s]Loss: -72.43Std: 0.0:  13%|█▎        | 64/500 [00:05<00:19, 22.28it/s]Loss: -72.44Std: 0.01:  13%|█▎        | 64/500 [00:05<00:19, 22.28it/s]Loss: -72.46Std: 0.01:  13%|█▎        | 64/500 [00:05<00:19, 22.28it/s]Loss: -72.47Std: 0.01:  13%|█▎        | 64/500 [00:05<00:19, 22.28it/s]Loss: -72.47Std: 0.01:  13%|█▎        | 67/500 [00:05<00:19, 22.58it/s]Loss: -72.48Std: 0.0:  13%|█▎        | 67/500 [00:05<00:19, 22.58it/s] Loss: -72.49Std: 0.01:  13%|█▎        | 67/500 [00:05<00:19, 22.58it/s]Loss: -72.48Std: 0.01:  13%|█▎        | 67/500 [00:05<00:19, 22.58it/s]Loss: -72.48Std: 0.01:  14%|█▍        | 70/500 [00:05<00:18, 22.80it/s]Loss: -72.48Std: 0.01:  14%|█▍        | 70/500 [00:05<00:18, 22.80it/s]Loss: -72.46Std: 0.02:  14%|█▍        | 70/500 [00:05<00:18, 22.80it/s]Loss: -72.45Std: 0.04:  14%|█▍        | 70/500 [00:05<00:18, 22.80it/s]Loss: -72.45Std: 0.04:  15%|█▍        | 73/500 [00:05<00:18, 22.95it/s]Loss: -72.45Std: 0.03:  15%|█▍        | 73/500 [00:05<00:18, 22.95it/s]Loss: -72.45Std: 0.03:  15%|█▍        | 73/500 [00:05<00:18, 22.95it/s]Loss: -72.45Std: 0.04:  15%|█▍        | 73/500 [00:05<00:18, 22.95it/s]Loss: -72.45Std: 0.04:  15%|█▌        | 76/500 [00:05<00:18, 23.06it/s]Loss: -72.43Std: 0.05:  15%|█▌        | 76/500 [00:05<00:18, 23.06it/s]Loss: -72.42Std: 0.05:  15%|█▌        | 76/500 [00:05<00:18, 23.06it/s]Loss: -72.42Std: 0.06:  15%|█▌        | 76/500 [00:05<00:18, 23.06it/s]Loss: -72.42Std: 0.06:  16%|█▌        | 79/500 [00:05<00:18, 23.14it/s]Loss: -72.4Std: 0.07:  16%|█▌        | 79/500 [00:06<00:18, 23.14it/s] Loss: -72.42Std: 0.05:  16%|█▌        | 79/500 [00:06<00:18, 23.14it/s]Loss: -72.4Std: 0.07:  16%|█▌        | 79/500 [00:06<00:18, 23.14it/s] Loss: -72.4Std: 0.07:  16%|█▋        | 82/500 [00:06<00:18, 23.20it/s]Loss: -72.39Std: 0.07:  16%|█▋        | 82/500 [00:06<00:18, 23.20it/s]Loss: -72.39Std: 0.07:  16%|█▋        | 82/500 [00:06<00:18, 23.20it/s]Loss: -72.39Std: 0.06:  16%|█▋        | 82/500 [00:06<00:18, 23.20it/s]Loss: -72.39Std: 0.06:  17%|█▋        | 85/500 [00:06<00:17, 23.22it/s]Loss: -72.39Std: 0.06:  17%|█▋        | 85/500 [00:06<00:17, 23.22it/s]Loss: -72.4Std: 0.05:  17%|█▋        | 85/500 [00:06<00:17, 23.22it/s] Loss: -72.39Std: 0.06:  17%|█▋        | 85/500 [00:06<00:17, 23.22it/s]Loss: -72.39Std: 0.06:  18%|█▊        | 88/500 [00:06<00:17, 23.26it/s]Loss: -72.39Std: 0.05:  18%|█▊        | 88/500 [00:06<00:17, 23.26it/s]Loss: -72.39Std: 0.05:  18%|█▊        | 88/500 [00:06<00:17, 23.26it/s]Loss: -72.4Std: 0.04:  18%|█▊        | 88/500 [00:06<00:17, 23.26it/s] Loss: -72.4Std: 0.04:  18%|█▊        | 91/500 [00:06<00:17, 23.27it/s]Loss: -72.39Std: 0.04:  18%|█▊        | 91/500 [00:06<00:17, 23.27it/s]Loss: -72.4Std: 0.03:  18%|█▊        | 91/500 [00:06<00:17, 23.27it/s] Loss: -72.38Std: 0.05:  18%|█▊        | 91/500 [00:06<00:17, 23.27it/s]Loss: -72.38Std: 0.05:  19%|█▉        | 94/500 [00:06<00:17, 23.28it/s]Loss: -72.39Std: 0.04:  19%|█▉        | 94/500 [00:06<00:17, 23.28it/s]Loss: -72.39Std: 0.03:  19%|█▉        | 94/500 [00:06<00:17, 23.28it/s]Loss: -72.41Std: 0.01:  19%|█▉        | 94/500 [00:06<00:17, 23.28it/s]Loss: -72.41Std: 0.01:  19%|█▉        | 97/500 [00:06<00:17, 23.28it/s]Loss: -72.42Std: 0.01:  19%|█▉        | 97/500 [00:06<00:17, 23.28it/s]Loss: -72.43Std: 0.01:  19%|█▉        | 97/500 [00:06<00:17, 23.28it/s]Loss: -72.38Std: 0.06:  19%|█▉        | 97/500 [00:06<00:17, 23.28it/s]Loss: -72.38Std: 0.06:  20%|██        | 100/500 [00:06<00:17, 23.18it/s]Loss: -72.35Std: 0.09:  20%|██        | 100/500 [00:06<00:17, 23.18it/s]Loss: -72.35Std: 0.08:  20%|██        | 100/500 [00:06<00:17, 23.18it/s]Loss: -72.36Std: 0.07:  20%|██        | 100/500 [00:07<00:17, 23.18it/s]Loss: -72.36Std: 0.07:  21%|██        | 103/500 [00:07<00:17, 23.23it/s]Loss: -72.36Std: 0.06:  21%|██        | 103/500 [00:07<00:17, 23.23it/s]Loss: -72.34Std: 0.08:  21%|██        | 103/500 [00:07<00:17, 23.23it/s]Loss: -72.33Std: 0.08:  21%|██        | 103/500 [00:07<00:17, 23.23it/s]Loss: -72.33Std: 0.08:  21%|██        | 106/500 [00:07<00:16, 23.25it/s]Loss: -72.33Std: 0.08:  21%|██        | 106/500 [00:07<00:16, 23.25it/s]Loss: -72.35Std: 0.05:  21%|██        | 106/500 [00:07<00:16, 23.25it/s]Loss: -72.35Std: 0.05:  21%|██        | 106/500 [00:07<00:16, 23.25it/s]Loss: -72.35Std: 0.05:  22%|██▏       | 109/500 [00:07<00:16, 23.27it/s]Loss: -72.35Std: 0.05:  22%|██▏       | 109/500 [00:07<00:16, 23.27it/s]Loss: -72.3Std: 0.1:  22%|██▏       | 109/500 [00:07<00:16, 23.27it/s]  Loss: -72.31Std: 0.09:  22%|██▏       | 109/500 [00:07<00:16, 23.27it/s]Loss: -72.31Std: 0.09:  22%|██▏       | 112/500 [00:07<00:16, 23.30it/s]Loss: -72.3Std: 0.09:  22%|██▏       | 112/500 [00:07<00:16, 23.30it/s] Loss: -72.32Std: 0.06:  22%|██▏       | 112/500 [00:07<00:16, 23.30it/s]Loss: -72.32Std: 0.07:  22%|██▏       | 112/500 [00:07<00:16, 23.30it/s]Loss: -72.32Std: 0.07:  23%|██▎       | 115/500 [00:07<00:16, 23.31it/s]Loss: -72.31Std: 0.06:  23%|██▎       | 115/500 [00:07<00:16, 23.31it/s]Loss: -72.3Std: 0.07:  23%|██▎       | 115/500 [00:07<00:16, 23.31it/s] Loss: -72.3Std: 0.07:  23%|██▎       | 115/500 [00:07<00:16, 23.31it/s]Loss: -72.3Std: 0.07:  24%|██▎       | 118/500 [00:07<00:16, 23.32it/s]Loss: -72.29Std: 0.07:  24%|██▎       | 118/500 [00:07<00:16, 23.32it/s]Loss: -72.35Std: 0.02:  24%|██▎       | 118/500 [00:07<00:16, 23.32it/s]Loss: -72.37Std: 0.0:  24%|██▎       | 118/500 [00:07<00:16, 23.32it/s] Loss: -72.37Std: 0.0:  24%|██▍       | 121/500 [00:07<00:16, 23.32it/s]Loss: -72.35Std: 0.02:  24%|██▍       | 121/500 [00:07<00:16, 23.32it/s]Loss: -72.35Std: 0.02:  24%|██▍       | 121/500 [00:07<00:16, 23.32it/s]Loss: -72.35Std: 0.02:  24%|██▍       | 121/500 [00:07<00:16, 23.32it/s]Loss: -72.35Std: 0.02:  25%|██▍       | 124/500 [00:07<00:16, 23.33it/s]Loss: -72.36Std: 0.0:  25%|██▍       | 124/500 [00:07<00:16, 23.33it/s] Loss: -72.36Std: 0.0:  25%|██▍       | 124/500 [00:08<00:16, 23.33it/s]Loss: -72.36Std: 0.01:  25%|██▍       | 124/500 [00:08<00:16, 23.33it/s]Loss: -72.36Std: 0.01:  25%|██▌       | 127/500 [00:08<00:15, 23.32it/s]Loss: -72.34Std: 0.02:  25%|██▌       | 127/500 [00:08<00:15, 23.32it/s]Loss: -72.34Std: 0.02:  25%|██▌       | 127/500 [00:08<00:15, 23.32it/s]Loss: -72.33Std: 0.03:  25%|██▌       | 127/500 [00:08<00:15, 23.32it/s]Loss: -72.33Std: 0.03:  26%|██▌       | 130/500 [00:08<00:15, 23.32it/s]Loss: -72.38Std: 0.01:  26%|██▌       | 130/500 [00:08<00:15, 23.32it/s]Loss: -72.38Std: 0.01:  26%|██▌       | 130/500 [00:08<00:15, 23.32it/s]Loss: -72.37Std: 0.02:  26%|██▌       | 130/500 [00:08<00:15, 23.32it/s]Loss: -72.37Std: 0.02:  27%|██▋       | 133/500 [00:08<00:15, 23.33it/s]Loss: -72.38Std: 0.01:  27%|██▋       | 133/500 [00:08<00:15, 23.33it/s]Loss: -72.39Std: 0.0:  27%|██▋       | 133/500 [00:08<00:15, 23.33it/s] Loss: -72.38Std: 0.0:  27%|██▋       | 133/500 [00:08<00:15, 23.33it/s]Loss: -72.38Std: 0.0:  27%|██▋       | 136/500 [00:08<00:15, 23.33it/s]Loss: -72.39Std: 0.0:  27%|██▋       | 136/500 [00:08<00:15, 23.33it/s]Loss: -72.38Std: 0.01:  27%|██▋       | 136/500 [00:08<00:15, 23.33it/s]Loss: -72.37Std: 0.01:  27%|██▋       | 136/500 [00:08<00:15, 23.33it/s]Loss: -72.37Std: 0.01:  28%|██▊       | 139/500 [00:08<00:15, 23.33it/s]Loss: -72.38Std: 0.0:  28%|██▊       | 139/500 [00:08<00:15, 23.33it/s] Loss: -72.38Std: 0.0:  28%|██▊       | 139/500 [00:08<00:15, 23.33it/s]Loss: -72.39Std: 0.0:  28%|██▊       | 139/500 [00:08<00:15, 23.33it/s]Loss: -72.39Std: 0.0:  28%|██▊       | 142/500 [00:08<00:15, 23.32it/s]Loss: -72.39Std: 0.0:  28%|██▊       | 142/500 [00:08<00:15, 23.32it/s]Loss: -72.39Std: 0.0:  28%|██▊       | 142/500 [00:08<00:15, 23.32it/s]Loss: -72.38Std: 0.01:  28%|██▊       | 142/500 [00:08<00:15, 23.32it/s]Loss: -72.38Std: 0.01:  29%|██▉       | 145/500 [00:08<00:15, 23.33it/s]Loss: -72.39Std: 0.0:  29%|██▉       | 145/500 [00:08<00:15, 23.33it/s] Loss: -72.39Std: 0.0:  29%|██▉       | 145/500 [00:08<00:15, 23.33it/s]Loss: -72.4Std: 0.0:  29%|██▉       | 145/500 [00:08<00:15, 23.33it/s] Loss: -72.4Std: 0.0:  30%|██▉       | 148/500 [00:08<00:15, 23.32it/s]Loss: -72.4Std: 0.0:  30%|██▉       | 148/500 [00:08<00:15, 23.32it/s]Loss: -72.42Std: 0.01:  30%|██▉       | 148/500 [00:09<00:15, 23.32it/s]Loss: -72.43Std: 0.0:  30%|██▉       | 148/500 [00:09<00:15, 23.32it/s] Loss: -72.43Std: 0.0:  30%|███       | 151/500 [00:09<00:15, 23.21it/s]Loss: -72.43Std: 0.0:  30%|███       | 151/500 [00:09<00:15, 23.21it/s]Loss: -72.44Std: 0.01:  30%|███       | 151/500 [00:09<00:15, 23.21it/s]Loss: -72.44Std: 0.01:  30%|███       | 151/500 [00:09<00:15, 23.21it/s]Loss: -72.44Std: 0.01:  31%|███       | 154/500 [00:09<00:14, 23.25it/s]Loss: -72.44Std: 0.01:  31%|███       | 154/500 [00:09<00:14, 23.25it/s]Loss: -72.45Std: 0.0:  31%|███       | 154/500 [00:09<00:14, 23.25it/s] Loss: -72.45Std: 0.01:  31%|███       | 154/500 [00:09<00:14, 23.25it/s]Loss: -72.45Std: 0.01:  31%|███▏      | 157/500 [00:09<00:14, 23.27it/s]Loss: -72.46Std: 0.0:  31%|███▏      | 157/500 [00:09<00:14, 23.27it/s] Loss: -72.47Std: 0.01:  31%|███▏      | 157/500 [00:09<00:14, 23.27it/s]Loss: -72.47Std: 0.01:  31%|███▏      | 157/500 [00:09<00:14, 23.27it/s]Loss: -72.47Std: 0.01:  32%|███▏      | 160/500 [00:09<00:14, 23.28it/s]Loss: -72.48Std: 0.0:  32%|███▏      | 160/500 [00:09<00:14, 23.28it/s] Loss: -72.48Std: 0.01:  32%|███▏      | 160/500 [00:09<00:14, 23.28it/s]Loss: -72.48Std: 0.01:  32%|███▏      | 160/500 [00:09<00:14, 23.28it/s]Loss: -72.48Std: 0.01:  33%|███▎      | 163/500 [00:09<00:14, 23.29it/s]Loss: -72.47Std: 0.02:  33%|███▎      | 163/500 [00:09<00:14, 23.29it/s]Loss: -72.48Std: 0.01:  33%|███▎      | 163/500 [00:09<00:14, 23.29it/s]Loss: -72.48Std: 0.0:  33%|███▎      | 163/500 [00:09<00:14, 23.29it/s] Loss: -72.48Std: 0.0:  33%|███▎      | 166/500 [00:09<00:14, 23.30it/s]Loss: -72.49Std: 0.0:  33%|███▎      | 166/500 [00:09<00:14, 23.30it/s]Loss: -72.49Std: 0.01:  33%|███▎      | 166/500 [00:09<00:14, 23.30it/s]Loss: -72.38Std: 0.12:  33%|███▎      | 166/500 [00:09<00:14, 23.30it/s]Loss: -72.38Std: 0.12:  34%|███▍      | 169/500 [00:09<00:14, 23.31it/s]Loss: -72.38Std: 0.12:  34%|███▍      | 169/500 [00:09<00:14, 23.31it/s]Loss: -72.38Std: 0.11:  34%|███▍      | 169/500 [00:09<00:14, 23.31it/s]Loss: -72.37Std: 0.11:  34%|███▍      | 169/500 [00:09<00:14, 23.31it/s]Loss: -72.37Std: 0.11:  34%|███▍      | 172/500 [00:09<00:14, 23.30it/s]Loss: -72.37Std: 0.11:  34%|███▍      | 172/500 [00:10<00:14, 23.30it/s]Loss: -72.35Std: 0.12:  34%|███▍      | 172/500 [00:10<00:14, 23.30it/s]Loss: -72.34Std: 0.13:  34%|███▍      | 172/500 [00:10<00:14, 23.30it/s]Loss: -72.34Std: 0.13:  35%|███▌      | 175/500 [00:10<00:13, 23.30it/s]Loss: -72.33Std: 0.13:  35%|███▌      | 175/500 [00:10<00:13, 23.30it/s]Loss: -72.34Std: 0.11:  35%|███▌      | 175/500 [00:10<00:13, 23.30it/s]Loss: -72.34Std: 0.11:  35%|███▌      | 175/500 [00:10<00:13, 23.30it/s]Loss: -72.34Std: 0.11:  36%|███▌      | 178/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.1:  36%|███▌      | 178/500 [00:10<00:13, 23.31it/s] Loss: -72.34Std: 0.09:  36%|███▌      | 178/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.09:  36%|███▌      | 178/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.09:  36%|███▌      | 181/500 [00:10<00:13, 23.30it/s]Loss: -72.34Std: 0.08:  36%|███▌      | 181/500 [00:10<00:13, 23.30it/s]Loss: -72.35Std: 0.08:  36%|███▌      | 181/500 [00:10<00:13, 23.30it/s]Loss: -72.36Std: 0.06:  36%|███▌      | 181/500 [00:10<00:13, 23.30it/s]Loss: -72.36Std: 0.06:  37%|███▋      | 184/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.07:  37%|███▋      | 184/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.07:  37%|███▋      | 184/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.07:  37%|███▋      | 184/500 [00:10<00:13, 23.31it/s]Loss: -72.34Std: 0.07:  37%|███▋      | 187/500 [00:10<00:13, 23.30it/s]Loss: -72.35Std: 0.06:  37%|███▋      | 187/500 [00:10<00:13, 23.30it/s]Loss: -72.46Std: 0.06:  37%|███▋      | 187/500 [00:10<00:13, 23.30it/s]Loss: -72.46Std: 0.05:  37%|███▋      | 187/500 [00:10<00:13, 23.30it/s]Loss: -72.46Std: 0.05:  38%|███▊      | 190/500 [00:10<00:13, 23.31it/s]Loss: -72.47Std: 0.05:  38%|███▊      | 190/500 [00:10<00:13, 23.31it/s]Loss: -72.48Std: 0.04:  38%|███▊      | 190/500 [00:10<00:13, 23.31it/s]Loss: -72.5Std: 0.01:  38%|███▊      | 190/500 [00:10<00:13, 23.31it/s] Loss: -72.5Std: 0.01:  39%|███▊      | 193/500 [00:10<00:13, 23.31it/s]Loss: -72.51Std: 0.0:  39%|███▊      | 193/500 [00:10<00:13, 23.31it/s]Loss: -72.53Std: 0.01:  39%|███▊      | 193/500 [00:10<00:13, 23.31it/s]Loss: -72.53Std: 0.01:  39%|███▊      | 193/500 [00:11<00:13, 23.31it/s]Loss: -72.53Std: 0.01:  39%|███▉      | 196/500 [00:11<00:13, 23.31it/s]Loss: -72.54Std: 0.0:  39%|███▉      | 196/500 [00:11<00:13, 23.31it/s] Loss: -72.53Std: 0.01:  39%|███▉      | 196/500 [00:11<00:13, 23.31it/s]Loss: -72.51Std: 0.03:  39%|███▉      | 196/500 [00:11<00:13, 23.31it/s]Loss: -72.51Std: 0.03:  40%|███▉      | 199/500 [00:11<00:12, 23.31it/s]Loss: -72.5Std: 0.03:  40%|███▉      | 199/500 [00:11<00:12, 23.31it/s] Loss: -72.51Std: 0.02:  40%|███▉      | 199/500 [00:11<00:12, 23.31it/s]Loss: -72.53Std: 0.01:  40%|███▉      | 199/500 [00:11<00:12, 23.31it/s]Loss: -72.53Std: 0.01:  40%|████      | 202/500 [00:11<00:12, 23.20it/s]Loss: -72.42Std: 0.11:  40%|████      | 202/500 [00:11<00:12, 23.20it/s]Loss: -72.42Std: 0.1:  40%|████      | 202/500 [00:11<00:12, 23.20it/s] Loss: -72.45Std: 0.07:  40%|████      | 202/500 [00:11<00:12, 23.20it/s]Loss: -72.45Std: 0.07:  41%|████      | 205/500 [00:11<00:12, 23.24it/s]Loss: -72.45Std: 0.07:  41%|████      | 205/500 [00:11<00:12, 23.24it/s]Loss: -72.45Std: 0.06:  41%|████      | 205/500 [00:11<00:12, 23.24it/s]Loss: -72.44Std: 0.07:  41%|████      | 205/500 [00:11<00:12, 23.24it/s]Loss: -72.44Std: 0.07:  42%|████▏     | 208/500 [00:11<00:12, 23.27it/s]Loss: -72.44Std: 0.07:  42%|████▏     | 208/500 [00:11<00:12, 23.27it/s]Loss: -72.44Std: 0.07:  42%|████▏     | 208/500 [00:11<00:12, 23.27it/s]Loss: -72.42Std: 0.08:  42%|████▏     | 208/500 [00:11<00:12, 23.27it/s]Loss: -72.42Std: 0.08:  42%|████▏     | 211/500 [00:11<00:12, 23.28it/s]Loss: -72.42Std: 0.08:  42%|████▏     | 211/500 [00:11<00:12, 23.28it/s]Loss: -72.41Std: 0.08:  42%|████▏     | 211/500 [00:11<00:12, 23.28it/s]Loss: -72.42Std: 0.07:  42%|████▏     | 211/500 [00:11<00:12, 23.28it/s]Loss: -72.42Std: 0.07:  43%|████▎     | 214/500 [00:11<00:12, 23.29it/s]Loss: -72.4Std: 0.08:  43%|████▎     | 214/500 [00:11<00:12, 23.29it/s] Loss: -72.4Std: 0.08:  43%|████▎     | 214/500 [00:11<00:15, 18.10it/s]

Converged with loss: -72.4
Psi Metric is {} and ideally should be less than 0.5.  The Prop Metric is {} and ideally should be greater than 0.5, where 1.0 is best
Preparting to save posteriors
Running 200 simulations.:   0%|          | 0/200 [00:00<?, ?it/s]Running 200 simulations.:   6%|▌         | 11/200 [00:00<00:01, 101.94it/s]Running 200 simulations.:  11%|█         | 22/200 [00:00<00:01, 98.71it/s] Running 200 simulations.:  16%|█▋        | 33/200 [00:00<00:01, 86.55it/s]Running 200 simulations.:  21%|██        | 42/200 [00:00<00:03, 47.99it/s]Running 200 simulations.:  25%|██▌       | 50/200 [00:00<00:02, 51.23it/s]Running 200 simulations.:  28%|██▊       | 57/200 [00:01<00:02, 49.27it/s]Running 200 simulations.:  33%|███▎      | 66/200 [00:01<00:02, 55.98it/s]Running 200 simulations.:  38%|███▊      | 77/200 [00:01<00:01, 67.03it/s]Running 200 simulations.:  42%|████▎     | 85/200 [00:01<00:02, 43.83it/s]Running 200 simulations.:  46%|████▌     | 91/200 [00:01<00:02, 46.13it/s]Running 200 simulations.:  48%|████▊     | 97/200 [00:01<00:02, 48.53it/s]Running 200 simulations.:  52%|█████▏    | 103/200 [00:02<00:02, 38.30it/s]Running 200 simulations.:  55%|█████▍    | 109/200 [00:02<00:02, 41.92it/s]Running 200 simulations.:  58%|█████▊    | 116/200 [00:02<00:01, 46.88it/s]Running 200 simulations.:  61%|██████    | 122/200 [00:02<00:02, 38.17it/s]Running 200 simulations.:  64%|██████▎   | 127/200 [00:02<00:02, 34.42it/s]Running 200 simulations.:  72%|███████▏  | 144/200 [00:02<00:00, 58.10it/s]Running 200 simulations.:  76%|███████▌  | 151/200 [00:02<00:00, 55.38it/s]Running 200 simulations.:  79%|███████▉  | 158/200 [00:03<00:01, 40.97it/s]Running 200 simulations.:  82%|████████▏ | 164/200 [00:03<00:00, 43.85it/s]Running 200 simulations.:  85%|████████▌ | 170/200 [00:03<00:00, 37.86it/s]Running 200 simulations.:  88%|████████▊ | 177/200 [00:03<00:00, 41.83it/s]Running 200 simulations.:  91%|█████████ | 182/200 [00:03<00:00, 38.82it/s]Running 200 simulations.:  95%|█████████▌| 190/200 [00:03<00:00, 44.57it/s]Running 200 simulations.:  98%|█████████▊| 196/200 [00:04<00:00, 46.54it/s]Running 200 simulations.: 100%|██████████| 200/200 [00:04<00:00, 46.21it/s]
Inferring posterior for round 1

Using SNPE-C with atomic loss
 Training neural network. Epochs trained: 1 Training neural network. Epochs trained: 2 Training neural network. Epochs trained: 3 Training neural network. Epochs trained: 4 Training neural network. Epochs trained: 5 Training neural network. Epochs trained: 6 Training neural network. Epochs trained: 7 Training neural network. Epochs trained: 8 Training neural network. Epochs trained: 9 Training neural network. Epochs trained: 10 Training neural network. Epochs trained: 11 Training neural network. Epochs trained: 12 Training neural network. Epochs trained: 13 Training neural network. Epochs trained: 14 Training neural network. Epochs trained: 15 Training neural network. Epochs trained: 16 Training neural network. Epochs trained: 17 Training neural network. Epochs trained: 18 Training neural network. Epochs trained: 19 Training neural network. Epochs trained: 20 Training neural network. Epochs trained: 21 Training neural network. Epochs trained: 22 Training neural network. Epochs trained: 23 Training neural network. Epochs trained: 24 Training neural network. Epochs trained: 25 Training neural network. Epochs trained: 26 Training neural network. Epochs trained: 27 Training neural network. Epochs trained: 28 Training neural network. Epochs trained: 29 Training neural network. Epochs trained: 30 Training neural network. Epochs trained: 31 Training neural network. Epochs trained: 32 Training neural network. Epochs trained: 33 Training neural network. Epochs trained: 34 Training neural network. Epochs trained: 35 Training neural network. Epochs trained: 36 Training neural network. Epochs trained: 37 Training neural network. Epochs trained: 38 Training neural network. Epochs trained: 39 Training neural network. Epochs trained: 40 Training neural network. Epochs trained: 41 Training neural network. Epochs trained: 42 Training neural network. Epochs trained: 43 Training neural network. Epochs trained: 44 Training neural network. Epochs trained: 45 Training neural network. Epochs trained: 46 Training neural network. Epochs trained: 47 Training neural network. Epochs trained: 48 Training neural network. Epochs trained: 49 Training neural network. Epochs trained: 50 Training neural network. Epochs trained: 51 Training neural network. Epochs trained: 52 Training neural network. Epochs trained: 53 Training neural network. Epochs trained: 54 Training neural network. Epochs trained: 55 Training neural network. Epochs trained: 56 Training neural network. Epochs trained: 57 Training neural network. Epochs trained: 58 Training neural network. Epochs trained: 59 Training neural network. Epochs trained: 60 Training neural network. Epochs trained: 61 Training neural network. Epochs trained: 62 Training neural network. Epochs trained: 63 Training neural network. Epochs trained: 64 Training neural network. Epochs trained: 65 Training neural network. Epochs trained: 66 Training neural network. Epochs trained: 67 Training neural network. Epochs trained: 68 Training neural network. Epochs trained: 69 Training neural network. Epochs trained: 70 Training neural network. Epochs trained: 71 Training neural network. Epochs trained: 72 Training neural network. Epochs trained: 73 Training neural network. Epochs trained: 74 Training neural network. Epochs trained: 75 Training neural network. Epochs trained: 76 Training neural network. Epochs trained: 77 Training neural network. Epochs trained: 78 Training neural network. Epochs trained: 79 Training neural network. Epochs trained: 80 Training neural network. Epochs trained: 81 Training neural network. Epochs trained: 82 Training neural network. Epochs trained: 83 Training neural network. Epochs trained: 84 Training neural network. Epochs trained: 85 Training neural network. Epochs trained: 86 Training neural network. Epochs trained: 87 Training neural network. Epochs trained: 88 Training neural network. Epochs trained: 89 Training neural network. Epochs trained: 90 Training neural network. Epochs trained: 91 Training neural network. Epochs trained: 92 Training neural network. Epochs trained: 93 Training neural network. Epochs trained: 94 Training neural network. Epochs trained: 95 Training neural network. Epochs trained: 96 Training neural network. Epochs trained: 97 Training neural network. Epochs trained: 98 Training neural network. Epochs trained: 99 Training neural network. Epochs trained: 100 Training neural network. Epochs trained: 101 Training neural network. Epochs trained: 102 Training neural network. Epochs trained: 103 Training neural network. Epochs trained: 104 Neural network successfully converged after 104 epochs.
        -------------------------
        ||||| ROUND 2 STATS |||||:
        -------------------------
        Epochs trained: 104
        Best validation performance: 3.7287
        -------------------------
        

 ****************************************** Building Posterior for round 1 ******************************************.

Training to emperical observation
Traceback (most recent call last):
  File "posterior_parallelpopgensim_ac_nfe_missense_sparse.py", line 471, in <module>
    app.run(main)
  File "/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "posterior_parallelpopgensim_ac_nfe_missense_sparse.py", line 353, in main
    posterior_build = posterior.train(n_particles=10, max_num_iters=500, quality_control=False)
  File "/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/sbi/inference/posteriors/vi_posterior.py", line 414, in train
    x = atleast_2d_float32_tensor(self._x_else_default_x(x)).to(  # type: ignore
  File "/project/jjberg/mehta5/SimulationDFE/SFS/lib/python3.8/site-packages/sbi/inference/posteriors/base_posterior.py", line 141, in _x_else_default_x
    raise ValueError(
ValueError: Context `x` needed when a default has not been set.If you'd like to have a default, use the `.set_default_x()` method.

 ****************************************** Completely finished experiment ****************************************** 
