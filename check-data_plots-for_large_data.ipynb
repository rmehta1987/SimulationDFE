{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/PopGen/SimulationSFS/SFS/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/rahul/PopGen/SimulationSFS/SFS/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/rahul/PopGen/SimulationSFS/SFS/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi, SNLE, MNLE, SNRE, SNRE_A\n",
    "from sbi.utils.posterior_ensemble import NeuralPosteriorEnsemble\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.utils import MultipleIndependent\n",
    "from sbi.neural_nets.embedding_nets import PermutationInvariantEmbedding, FCEmbedding\n",
    "from sbi.utils.user_input_checks import process_prior, process_simulator\n",
    "from sbi.utils import get_density_thresholder, RestrictedPrior\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "import numpy as np\n",
    "import moments\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import atexit\n",
    "import torch.nn.functional as F\n",
    "import subprocess\n",
    "import sparselinear as sl\n",
    "from sortedcontainers import SortedDict\n",
    "from scipy.spatial import KDTree\n",
    "import os\n",
    "import re\n",
    "from monarch_linear import MonarchLinear\n",
    "import pdb\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR) # See: https://github.com/matplotlib/matplotlib/issues/14523\n",
    "from collections import defaultdict\n",
    "from sbi.analysis import pairplot\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=55855\n",
    "the_device='cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryNet(nn.Module):\n",
    "    def __init__(self, sample_size, block_sizes, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.sample_size = sample_size # For monarch this needs to be divisible by the block size\n",
    "        self.block_size = block_sizes\n",
    "        self.linear4 = MonarchLinear(sample_size, int(sample_size / 10), nblocks=self.block_size[0]) # 11171\n",
    "        self.linear5 = MonarchLinear(int(self.sample_size / 10), int(self.sample_size / 10) , nblocks=self.block_size[1]) # 11171\n",
    "        self.linear6 = MonarchLinear(int(self.sample_size / 10), int(self.sample_size / 10), nblocks=self.block_size[2]) # 11171\n",
    "\n",
    "        self.model = nn.Sequential(self.linear4, nn.Dropout(dropout_rate), nn.GELU(),\n",
    "                                   self.linear5, nn.Dropout(dropout_rate), nn.GELU(),\n",
    "                                   self.linear6) \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_datafrom_hdf5(path_to_sim_file: str):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        path_to_sim_file (str): _description_\n",
    "    \"\"\"    \n",
    "    #TODO probably will be better to use https://github.com/quantopian/warp_prism for faster look-up tables\n",
    "    global loaded_file \n",
    "    global loaded_file_keys\n",
    "    global loaded_tree\n",
    "    import h5py\n",
    "    loaded_file = h5py.File(path_to_sim_file, 'r')\n",
    "    loaded_file_keys = list(loaded_file.keys())\n",
    "    loaded_tree = KDTree(np.asarray(loaded_file_keys)[:,None]) # needs to have a column dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregated_generate_sim_data(prior: float) -> torch.float32:\n",
    "\n",
    "    data = np.zeros((sample_size*2-2))\n",
    "    theprior = prior[:-1] # last dim is misidentification\n",
    "    gammas = -1*10**(theprior.cpu().numpy().squeeze())\n",
    "    #theprior=prior\n",
    "    #mis_id = prior[-1].cpu().numpy()\n",
    "    mis_id=0\n",
    "    for a_prior in gammas:\n",
    "        _, idx = loaded_tree.query(a_prior, k=(1,)) # the k sets number of neighbors, while we only want 1, we need to make sure it returns an array that can be indexed\n",
    "        fs = loaded_file[loaded_file_keys[idx[0]]][:]\n",
    "        fs = fs[1:] # because 0th bin is monomorphic sites\n",
    "        fs = (1 - mis_id)*fs + mis_id * fs[::-1]\n",
    "        data += fs \n",
    "    data /= theprior.shape[0]\n",
    "    return torch.exp(torch.log(torch.nn.functional.relu(torch.tensor(data, device=the_device)+1)).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_true_data(a_path: str, type: int) -> torch.float32:\n",
    "    \"\"\"Loads a true SFS, note that the sample size must be consistent with the passed parameters\n",
    "\n",
    "    Args:\n",
    "        path (str): Where the true-SFS is located, must be a numpy array\n",
    "        type (int): is data stored in numpy pickle (0) or torch pickle (1)\n",
    "\n",
    "    Returns:\n",
    "        Returns the SFS of the true data-set\n",
    "    \"\"\"\n",
    "    if type == 0:\n",
    "        sfs = np.load(a_path)\n",
    "        sfs = torch.tensor(sfs, device=the_device).type(torch.float32)\n",
    "    else:\n",
    "        sfs = torch.load(a_path)\n",
    "        sfs.to(the_device)\n",
    "    assert sfs.shape[0] == sample_size*2-1, \"Sample Size must be the same dimensions as the Site Frequency Spectrum, SFS shape: {} and sample shape (2*N-1): {}\".format(sfs.shape[0], sample_size*2-1)\n",
    "\n",
    "    return sfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sim_datafrom_hdf5('sfs_lof_hdf5_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters from moments, gamma for lof\n",
    "# shape: 0.3589\n",
    "# scale: 7830.5\n",
    "gdist = torch.distributions.gamma.Gamma(torch.tensor([0.3589]),torch.tensor([1/7830.5]))\n",
    "gamma_samples = gdist.sample((1000,)).type(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal parameters (missense):\n",
    "#shape: 0.4448\n",
    "#scale: 82.4\n",
    "gdist2 = torch.distributions.gamma.Gamma(torch.tensor([0.4448]),torch.tensor([1/82.4]))\n",
    "gamma_samples = gdist.sample((1000,)).type(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udist = torch.distributions.uniform.Uniform(-6.0*torch.ones(50),4.0*torch.ones(50))\n",
    "uniform_samples = udist.sample((1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_posterior=torch.load('Experiments/saved_posteriors_nfe_lof_sinkhorn_2023-04-16_18-21/posterior_observed_round_3.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_x = (load_true_data('emperical_lof_sfs_nfe.npy', 0)[:-1]).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_reject_fn = get_density_thresholder(last_posterior, quantile=1e-5, num_samples_to_estimate_support=100000)\n",
    "proposal = RestrictedPrior(last_posterior._prior, accept_reject_fn, last_posterior, sample_with=\"sir\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fs=[]\n",
    "predicted_fs2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_samples = proposal.sample((1000,), oversampling_factor=1024)[:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with p_misid\n",
    "obs_samples2 = proposal.sample((1000,), oversampling_factor=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2524, -3.1463, -4.3128, -3.4795, -4.7999, -2.2794, -3.5330, -3.2717,\n",
       "        -3.5474, -2.9952, -3.2085, -3.3104, -3.7360, -3.5634, -3.8361, -3.0628],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(obs_samples,dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sampled selection coefficients: torch.Size([1000, 16])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of sampled selection coefficients: {}\".format(obs_samples.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:19<00:00, 50.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for obs_sample in tqdm(obs_samples):\n",
    "    fs = aggregated_generate_sim_data(obs_sample)\n",
    "    predicted_fs.append(fs.unsqueeze(0).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 113.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for obs_sample in tqdm(obs_samples2):\n",
    "    fs = generate_sim_data2(obs_sample)\n",
    "    predicted_fs2.append(fs.unsqueeze(0).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frequency spectrum containing all bins (1000, 111708)\n"
     ]
    }
   ],
   "source": [
    "new_predicted_fs = np.asarray(predicted_fs).squeeze(1)\n",
    "print(\"Shape of frequency spectrum containing all bins {}\".format(new_predicted_fs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frequency spectrum containing all bins (1000, 169)\n"
     ]
    }
   ],
   "source": [
    "new_predicted_fs2 = np.asarray(predicted_fs2).squeeze(1)\n",
    "print(\"Shape of frequency spectrum containing all bins {}\".format(new_predicted_fs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "for i in range(1, 25):\n",
    "    ax = fig.add_subplot(5, 5, i)\n",
    "    sns.histplot(np.log10(new_predicted_fs[:,i-1]))\n",
    "    plt.axvline(x=np.mean(np.log10(new_predicted_fs[:,i-1])), color='m', label=\"mean\")\n",
    "    plt.axvline(x=np.median(np.log10(new_predicted_fs[:,i-1])), color='k', label=\"median\")\n",
    "    ax.axline((np.log10(true_x[i-1]), 1), (np.log10(true_x[i-1]),100), marker='+', c='r', label=\"Emperical SFS\")\n",
    "    plt.title(\"Emperical SFS: 10^{:.3f} at bin: {}\".format(np.log10(true_x[i-1]),i))\n",
    "fig.legend([\"mean\", \"median\", \"Emperical SFS\"], loc=\"lower center\", ncol=4)\n",
    "plt.savefig('ppc_check_hist_mis_36_coefficients_round2_blur_2_hs.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "for i in range(1, 25):\n",
    "    ax = fig.add_subplot(5, 5, i)\n",
    "    sns.histplot(np.log10(new_predicted_fs2[:,i-1]))\n",
    "    plt.axvline(x=np.mean(np.log10(new_predicted_fs2[:,i-1])), color='m', label=\"mean\")\n",
    "    plt.axvline(x=np.median(np.log10(new_predicted_fs2[:,i-1])), color='k', label=\"median\")\n",
    "    ax.axline((np.log10(true_x[i-1]), 1), (np.log10(true_x[i-1]),100), marker='+', c='r', label=\"Emperical SFS\")\n",
    "    plt.title(\"Emperical SFS: 10^{:.3f} at bin: {}\".format(np.log10(true_x[i-1]),i))\n",
    "fig.legend([\"mean\", \"median\", \"Emperical SFS\"], loc=\"lower center\", ncol=4)\n",
    "plt.savefig('ppc_check_hist_lof_36_coefficients_round2_blur_2_s.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without pmsid: [48602.387 31738.643 23261.285 18186.506 14821.931 12434.978 10657.814\n",
      "  9285.689  8195.894  7310.463]\n",
      "tensor([[137812.,  26101.,  10321.,  ...,      0.,      0.,      0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "mean_predicted = np.mean(new_predicted_fs[:],axis=0)\n",
    "print(f\"Without pmsid: {mean_predicted[:10]}\")\n",
    "print(true_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 111708])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to create a normalized batch tensor of the predicted frequency spectrum\n",
    "temp = torch.tensor(predicted_fs)\n",
    "temp = temp.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_predicted_fs = temp/temp.sum(dim=1).view(temp.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp[0,:10])\n",
    "print(temp.sum(dim=1)[0])\n",
    "print(norm_predicted_fs[0,:10])\n",
    "# Test to create a normalized batch tensor of the predicted frequency spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frequency bins on x-axis for plotting 200\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(0,mean_predicted[:200].shape[0])\n",
    "print(\"Shape of frequency bins on x-axis for plotting {}\".format(x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=x,y=np.log10(mean_predicted[:200]+1), label=\"Predicted\")\n",
    "sns.scatterplot(x=x,y=np.log10(true_x.cpu().numpy()[0,:200]+1), label=\"Emperical\")\n",
    "plt.title(\"Mean of posterior predicted SFS vs True SFS\")\n",
    "plt.ylabel(\"Log Scaled Allele Frequency\")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "#fig.legend([\"Predicted\", \"Emperical\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('ppc_scatter_lof_nfe_round_3.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=x,y=np.log10(mean_predicted2+1), label=\"Predicted\")\n",
    "sns.scatterplot(x=x,y=np.log10(true_x+1), label=\"Emperical\")\n",
    "plt.title(\"Mean of posterior predicted SFS vs True SFS\")\n",
    "plt.ylabel(\"Log Scaled Allele Frequency\")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "#fig.legend([\"Predicted\", \"Emperical\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('ppc_scatter_mis_36_coefficients_round1.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 16])\n",
      "tensor([-3.2524, -3.1463, -4.3128, -3.4795, -4.7999, -2.2794, -3.5330, -3.2717,\n",
      "        -3.5474, -2.9952, -3.2085, -3.3104, -3.7360, -3.5634, -3.8361, -3.0628],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(obs_samples.shape)\n",
    "print(obs_samples.mean(dim=0))\n",
    "obs_samples2 = obs_samples.reshape(-1)\n",
    "\n",
    "samps = obs_samples2.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samps =last_posterior._prior.sample((2000,)).view(-1).cpu().numpy()\n",
    "gamma_samples2 = gdist.sample((1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.kdeplot(samps, label=\"DFE\", c='r')\n",
    "sns.kdeplot(prior_samps, label=\"Initial Proposal\", c='g')\n",
    "plt.title(\"Kernel Density Estimation Inferred Scaled Selection\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(\"Log of Absolute Scaled Selection Coefficient\")\n",
    "fig.legend([\"DFE\", \"Initial Proposal\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('ppc_nfe_selectiion_round3.png')\n",
    "plt.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe2= samps.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 <= |s| < 1e-05: 0.0000000\n",
      "1e-05 <= |s| < 0.0001: 0.0000000\n",
      "0.0001 <= |s| < 0.001: 0.0000000\n",
      "0.001 <= |s| < 0.01: 0.3749375\n",
      "0.01 <= |s| < 0.1: 0.0915938\n",
      "0.1 <= |s| < 1: 0.0851250\n",
      "1 <= |s| < 10000.0: 0.4483437\n",
      "|s| > 10000.0: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "bins = [-6, -5, -4, -3, -2, -1, 0, 4.0]\n",
    "for s0, s1 in zip(bins[:-1], bins[1:]):\n",
    "    the_dat=np.extract((s0 <= dfe2) & (dfe2 < s1), dfe2)\n",
    "    prop = the_dat.shape[0]/obs_samples2.shape[0]\n",
    "    print(f\"{10**s0} <= |s| < {10**s1}: {prop:.7f}\")\n",
    "    if s1 == bins[-1]:\n",
    "        the_dat=np.extract(dfe2 > s1, dfe2)\n",
    "        prop = the_dat.shape[0]/500000.0\n",
    "        print(f\"|s| > {10**s1}: {prop:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss between true and predicted in poisson log-liklihood\n",
    "loss = -1*torch.nn.functional.poisson_nll_loss(torch.log(torch.tensor(mean_predicted2+1)), torch.log(torch.tensor(true_x+1)),log_input=True, full=False, reduction='sum' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_predicted = torch.log(torch.tensor(new_predicted_fs).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_target = torch.log(torch.tensor(true_x+1).repeat(log_predicted.shape[0],1).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = -1*torch.nn.functional.poisson_nll_loss(log_predicted, log_target, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson log-liklihood loss -4795.529159783006 vs moments log-liklihood loss for lof -237.79096099886482\n"
     ]
    }
   ],
   "source": [
    "print(\"poisson log-liklihood loss {} vs moments log-liklihood loss for lof {}\".format(loss, moments_loss_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson log-liklihood loss over batch -47.59079092120809 vs moments log-liklihood loss for lof -237.79096099886482\n"
     ]
    }
   ],
   "source": [
    "print(\"poisson log-liklihood loss over batch {} vs moments log-liklihood loss for lof {}\".format(loss2, moments_loss_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = (mean_predicted - true_x)/np.sqrt(mean_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=x,y=resid, label=\"Residual\")\n",
    "plt.title(\"Poisson Residuals\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "#fig.legend([\"Predicted\", \"Emperical\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('resid_lof_32_coefficients_round10.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.5309, 5.0752, 4.4188, 4.0943, 3.6376, 3.1781, 3.1781, 2.6391, 2.5649,\n",
       "         2.7726, 2.7081, 2.7081, 2.7081, 2.7726, 2.3026, 1.0986, 2.3026, 2.3979,\n",
       "         1.6094, 1.9459, 1.3863, 1.6094, 1.3863, 1.9459, 1.9459, 1.7918, 1.3863,\n",
       "         1.6094, 1.0986, 1.0986, 1.6094, 1.7918, 2.0794, 1.6094, 1.0986, 1.6094,\n",
       "         2.0794, 0.6931, 1.0986, 1.3863, 1.3863, 0.6931, 1.0986, 0.6931, 0.0000,\n",
       "         1.0986, 0.6931, 1.0986, 0.6931, 0.6931, 0.0000, 1.0986, 1.0986, 0.6931,\n",
       "         1.0986, 1.0986, 0.6931, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6931,\n",
       "         0.0000, 0.6931, 0.6931, 0.6931, 0.0000, 0.0000, 0.6931, 0.6931, 0.0000,\n",
       "         0.6931, 0.6931, 1.3863, 0.6931, 0.6931, 0.0000, 0.6931, 0.6931, 0.0000,\n",
       "         0.0000, 0.0000, 1.3863, 0.6931, 0.6931, 0.6931, 0.0000, 0.6931, 0.6931,\n",
       "         1.0986, 0.0000, 0.6931, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0986,\n",
       "         0.0000, 0.0000, 0.0000, 0.6931, 0.0000, 0.6931, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6931,\n",
       "         0.0000, 0.6931, 0.6931, 0.0000, 0.0000, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.0000, 0.0000, 0.6931, 0.0000, 0.0000, 0.0000, 0.0000, 0.6931, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 1.0986, 0.0000, 0.0000, 0.6931, 0.6931, 1.0986, 0.6931, 0.6931,\n",
       "         0.0000, 0.0000, 0.0000, 0.6931, 0.0000, 0.6931, 0.6931, 1.0986, 0.0000,\n",
       "         0.0000, 0.0000, 1.0986, 0.0000, 0.6931, 0.0000, 0.6931]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c011ed9bb21179cd579adf84b3829b40600ff69d12d61fe328e5e2fbe10069c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
