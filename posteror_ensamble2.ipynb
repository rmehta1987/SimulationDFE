{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi, SNLE\n",
    "from sbi.utils.posterior_ensemble import NeuralPosteriorEnsemble\n",
    "import numpy as np\n",
    "import moments\n",
    "from sbi.utils import process_prior\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import dill\n",
    "import os\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from sbi.inference import infer\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Independent\n",
    "\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulator\n",
    "def momment_sim(prior):\n",
    "    \n",
    "    moment_data =  moments.Spectrum(moments.LinearSystem_1D.steady_state_1D(100, gamma=prior.detach().cpu().numpy(), theta=100.0))  # returns a masked array\n",
    "    # masked arrays are objects and data is accessed through .data attribute or valid data through .compressed()\n",
    "    actual_fs = moment_data.compressed()  \n",
    "    x = torch.poisson(torch.tensor(actual_fs))\n",
    "    return x.view(1,-1).type(torch.float32)\n",
    "\n",
    "def true_data(prior):\n",
    "    \n",
    "    if prior.shape[0] > 1:\n",
    "        moment_data =  moments.Spectrum(moments.LinearSystem_1D.steady_state_1D(100, gamma=prior[0].detach().cpu().numpy(), theta=100.0))\n",
    "        actual_fs = moment_data.compressed()  \n",
    "        x = torch.poisson(torch.tensor(actual_fs).repeat(prior.shape[0],1))\n",
    "    else:\n",
    "        moment_data =  moments.Spectrum(moments.LinearSystem_1D.steady_state_1D(100, gamma=prior.detach().cpu().numpy(), theta=100.0))\n",
    "        actual_fs = moment_data.compressed()  \n",
    "        x = torch.poisson(torch.tensor(actual_fs))\n",
    "    return x, actual_fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Prior\n",
    "boxprior = utils.BoxUniform(low=1 * torch.ones(1), high=100 * torch.ones(1), device='cuda')\n",
    "gamma_prior = torch.distributions.Gamma(100.0*torch.ones((1,),device='cuda'), 10.0*torch.ones((1,),device='cuda'))\n",
    "#prior, *_ = process_prior(gamma_prior)\n",
    "ind_gamma_prior = Independent(gamma_prior,reinterpreted_batch_ndims=1)\n",
    "pop_dim = 100\n",
    "prior=ind_gamma_prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 2\n",
    "prior_mean = torch.zeros(num_dim)\n",
    "prior_cov = torch.eye(num_dim)\n",
    "Normprior = MultivariateNormal(loc=prior_mean, covariance_matrix=prior_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normprior._event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9235]], device='cuda:0')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_prior.sample((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_prior._event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_gamma_prior._event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_prior._batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9889]], device='cuda:0')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior.sample((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[67.5278]], device='cuda:0')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxprior.sample((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SNLE\n",
    "#simulator, prior = prepare_for_sbi(momment_sim, prior)\n",
    "inferer = SNLE(prior, show_progress_bars=True, device='cuda', density_estimator=\"maf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta for true: tensor([[10.8689]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Obtain posterior samples for different number of iid \"observed\" xos.\n",
    "num_sim = 500\n",
    "num_iid_trials = num_sim # if not num_sim it will not run\n",
    "\n",
    "# Generate IID samples from the same prior value\n",
    "theta_o = prior.sample((1,))\n",
    "print(\"theta for true: {}\".format(theta_o))\n",
    "true_x, actual_fs = true_data(theta_o.repeat(num_iid_trials,1))\n",
    "true_x = true_x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posterior parameters\n",
    "vi_parameters = dict(q=\"maf\")\n",
    "vi_parameters_2 = dict(q=\"nsf\")\n",
    "\n",
    "rounds = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 99])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef3aeccf3b14a20b3e91bd763f66390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 21 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d82782bfc634cce8c4d608be7c7686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior conditional density p(Î¸|x) of type VIPosterior. It provides Variational inference to .sample() from the posterior and can evaluate the _normalized_ posterior density with .log_prob().\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(proposal)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     theta, x \u001b[39m=\u001b[39m simulate_for_sbi(momment_sim, proposal, num_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     liklihood_estimator \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39mappend_simulations(theta, x)\u001b[39m.\u001b[39mtrain(training_batch_size\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     potential_fn, theta_transform \u001b[39m=\u001b[39m likelihood_estimator_based_potential(liklihood_estimator, proposal,x_o\u001b[39m=\u001b[39mtrue_x[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/base.py:493\u001b[0m, in \u001b[0;36msimulate_for_sbi\u001b[0;34m(simulator, proposal, num_simulations, num_workers, simulation_batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimulate_for_sbi\u001b[39m(\n\u001b[1;32m    459\u001b[0m     simulator: Callable,\n\u001b[1;32m    460\u001b[0m     proposal: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    465\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m    466\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns ($\\theta, x$) pairs obtained from sampling the proposal and simulating.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[39m    This function performs two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39m    Returns: Sampled parameters $\\theta$ and simulation-outputs $x$.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     theta \u001b[39m=\u001b[39m proposal\u001b[39m.\u001b[39;49msample((num_simulations,))\n\u001b[1;32m    495\u001b[0m     x \u001b[39m=\u001b[39m simulate_in_batches(\n\u001b[1;32m    496\u001b[0m         simulator, theta, simulation_batch_size, num_workers, show_progress_bar\n\u001b[1;32m    497\u001b[0m     )\n\u001b[1;32m    499\u001b[0m     \u001b[39mreturn\u001b[39;00m theta, x\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/posteriors/vi_posterior.py:288\u001b[0m, in \u001b[0;36mVIPosterior.sample\u001b[0;34m(self, sample_shape, x, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"Samples from the variational posterior distribution.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \n\u001b[1;32m    281\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m    Samples from posterior.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x_else_default_x(x)\n\u001b[0;32m--> 288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trained_on \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (x \u001b[39m!=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trained_on)\u001b[39m.\u001b[39mall():\n\u001b[1;32m    289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    290\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe variational posterior was not fit on the specified `default_x` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m. Please train using `posterior.train()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    293\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq\u001b[39m.\u001b[39msample(torch\u001b[39m.\u001b[39mSize(sample_shape))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "from sbi.inference import likelihood_estimator_based_potential\n",
    "from sbi.inference.posteriors.vi_posterior import VIPosterior\n",
    "\n",
    "posteriors = []\n",
    "for i in range(0,rounds):\n",
    "    \n",
    "    if i == 0:\n",
    "        theta, x = simulate_for_sbi(momment_sim, prior, num_sim)\n",
    "        liklihood_estimator = inferer.append_simulations(theta, x).train(training_batch_size=50)\n",
    "        potential_fn, theta_transform = likelihood_estimator_based_potential(liklihood_estimator, prior,x_o=true_x[0])\n",
    "        a_post = VIPosterior(potential_fn=potential_fn,\n",
    "                        theta_transform=theta_transform,\n",
    "                        prior=prior, vi_method=\"IW\", q=\"nsf\")\n",
    "        posteriors.append(a_post)\n",
    "        proposal = a_post.train(max_num_iters=40, quality_control=False, K=50)\n",
    "    else:\n",
    "        print(proposal)\n",
    "        theta, x = simulate_for_sbi(momment_sim, proposal, num_sim)\n",
    "        \n",
    "        liklihood_estimator = inferer.append_simulations(theta, x).train(training_batch_size=50)\n",
    "        potential_fn, theta_transform = likelihood_estimator_based_potential(liklihood_estimator, proposal,x_o=true_x[0])\n",
    "        a_post = VIPosterior(potential_fn=potential_fn,\n",
    "                        theta_transform=theta_transform,\n",
    "                        prior=prior, vi_method=\"IW\", q=\"nsf\")\n",
    "        posteriors.append(a_post)\n",
    "        proposal = a_post.train(max_num_iters=40, quality_control=False, K=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db23f0aebaa24a4cb82f2eb394e30d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/utils/user_input_checks.py:702: UserWarning: Data x has device 'cpu'.Moving x to the data_device 'cuda:0'.Training will proceed on device 'cuda:0'.\n",
      "  warnings.warn(\n",
      "/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/neural_nets/flow.py:141: UserWarning: In one-dimensional output space, this flow is limited to Gaussians\n",
      "  warn(\"In one-dimensional output space, this flow is limited to Gaussians\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 25 epochs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/pyro/nn/auto_reg_nn.py:179: UserWarning: ConditionalAutoRegressiveNN input_dim = 1. Consider using an affine transformation instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9e290c5d694f78adc0e80087a332c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd926e851434bfda5beb82bc72c9b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 21 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4ea6ca17c04121ad89faaaa5414e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06eb46e732054afcae2c1ee951eb4327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 26 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b5f2eb183d4bd68844f0a6a3e3e39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f44bc6d0d2743a1a58bb524c5a95a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 27 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb3ab784e9b42cc89d64e6f77ed1ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c1d5624d434ebebd2d041ed52a16f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 25 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f5463ddbdc4e27bfbe23fb823d036b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d932c0e4de471db71858a3d97fc2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 24 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f86eb48e624c408a73b14356d8b5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc27ffde7a741299a7555f4d6f5d477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 23 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c651781f1743d7887666fd90948034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e72341b50045bbb628e49fcd8b8d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 25 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d5ca00b2e4824a816f32b68fa36a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be83a88819e64985a99f55d04d274c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 21 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a6ef1220d42acb33bf80213f2e268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7090c1ad0c436b802b2776b582d53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 26 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90efbc0e7e74fa980de513c73050e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b34c2230244dd2a9aa66b3eec70de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 22 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5a4897a26542628b66d9b1a5f9cff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e63a245f9bc4047b31dbd0c5bf82df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Training neural network. Epochs trained: 10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,rounds):\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     theta, x \u001b[39m=\u001b[39m simulate_for_sbi(momment_sim, prior, num_sim)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     liklihood_estimator \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39;49mappend_simulations(theta, x, proposal\u001b[39m=\u001b[39;49mproposal)\u001b[39m.\u001b[39;49mtrain(training_batch_size\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     posterior \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39mbuild_posterior(density_estimator\u001b[39m=\u001b[39mliklihood_estimator, sample_with \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvi\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                         vi_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfKL\u001b[39m\u001b[39m\"\u001b[39m, vi_parameters\u001b[39m=\u001b[39mvi_parameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     posteriors\u001b[39m.\u001b[39mappend(posterior)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/snpe/snpe_c.py:179\u001b[0m, in \u001b[0;36mSNPE_C.train\u001b[0;34m(self, num_atoms, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, use_combined_loss, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_non_atomic_loss:\n\u001b[1;32m    176\u001b[0m         \u001b[39m# Take care of z-scoring, pre-compute and store prior terms.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_state_for_mog_proposal()\n\u001b[0;32m--> 179\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/snpe/snpe_base.py:360\u001b[0m, in \u001b[0;36mPosteriorEstimator.train\u001b[0;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m train_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(train_losses)\n\u001b[1;32m    358\u001b[0m train_log_probs_sum \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m train_losses\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> 360\u001b[0m train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m clip_max_norm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     clip_grad_norm_(\n\u001b[1;32m    363\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_neural_net\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39mclip_max_norm\n\u001b[1;32m    364\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inferer = SNPE(prior, show_progress_bars=True, device='cuda', density_estimator=\"maf\")\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "for i in range(0,rounds):\n",
    "    \n",
    "\n",
    "    theta, x = simulate_for_sbi(momment_sim, prior, num_sim)\n",
    "    liklihood_estimator = inferer.append_simulations(theta, x, proposal=proposal).train(training_batch_size=50)\n",
    "    posterior = inferer.build_posterior(density_estimator=liklihood_estimator, sample_with = \"vi\", \n",
    "                                        vi_method=\"fKL\", vi_parameters=vi_parameters)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_x[0]).train(max_num_iters=40, quality_control=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4848d612778412294e8b8476128f96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 38 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b01526cce41416886cb9754a4d556a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec721b90f84a439cba5fb765b8f7e801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 35 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706273feeb434ef385469f07ccb941bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbc2b8680d746179eb53335d8af68fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 26 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6626bacf5ce24ecb8e51437af66bb1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9147590c94b4a21b44461ea0b636ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 23 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154434a27454486fa46d4bc41c9a2b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cbc23d5ef84c159e3accb7e3577ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 27 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2595de9155b34b10a49c7a93dbb27ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb5a6a1381c43f0be83266c2373b537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 27 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fbd448fdf74c8e9b608b4991749472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d73e7f299ff4f919a9df241092cb135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 24 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7496a375dbd342ffa79fc0cc787e898d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4303b53a67f44ff2b28cd174e225ada0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 32 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77f59dded8847daae5a17fde76edae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc42fd5ed910431ea7063108328f31bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 22 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328f14968f184f649500466e5f8b720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbb131e021a48b88d6d8303599566f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 26 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72379643d60457fa46b247abb6daa92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f58b57f2cd45af9d00fa25dd74faf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 21 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189eb03668e64352a254f9b491fef558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1126daa87e3549bca01448ac2066107f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid Poisson rate, expected rate to be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m proposal \u001b[39m=\u001b[39m prior\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,rounds):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     theta, x \u001b[39m=\u001b[39m simulate_for_sbi(momment_sim, proposal, num_sim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     liklihood_estimator \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39mappend_simulations(theta, x)\u001b[39m.\u001b[39mtrain(training_batch_size\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     posterior \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39mbuild_posterior(density_estimator\u001b[39m=\u001b[39mliklihood_estimator, sample_with \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvi\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                         vi_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfKL\u001b[39m\u001b[39m\"\u001b[39m, vi_parameters\u001b[39m=\u001b[39mvi_parameters)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/base.py:495\u001b[0m, in \u001b[0;36msimulate_for_sbi\u001b[0;34m(simulator, proposal, num_simulations, num_workers, simulation_batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns ($\\theta, x$) pairs obtained from sampling the proposal and simulating.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[39mThis function performs two steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39mReturns: Sampled parameters $\\theta$ and simulation-outputs $x$.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m theta \u001b[39m=\u001b[39m proposal\u001b[39m.\u001b[39msample((num_simulations,))\n\u001b[0;32m--> 495\u001b[0m x \u001b[39m=\u001b[39m simulate_in_batches(\n\u001b[1;32m    496\u001b[0m     simulator, theta, simulation_batch_size, num_workers, show_progress_bar\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[39mreturn\u001b[39;00m theta, x\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/simulators/simutils.py:88\u001b[0m, in \u001b[0;36msimulate_in_batches\u001b[0;34m(simulator, theta, sim_batch_size, num_workers, seed, show_progress_bars)\u001b[0m\n\u001b[1;32m     86\u001b[0m         simulation_outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m batches:\n\u001b[0;32m---> 88\u001b[0m             simulation_outputs\u001b[39m.\u001b[39mappend(simulator(batch))\n\u001b[1;32m     89\u001b[0m             pbar\u001b[39m.\u001b[39mupdate(sim_batch_size)\n\u001b[1;32m     91\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(simulation_outputs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb Cell 18\u001b[0m in \u001b[0;36mmomment_sim\u001b[0;34m(prior)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# masked arrays are objects and data is accessed through .data attribute or valid data through .compressed()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m actual_fs \u001b[39m=\u001b[39m moment_data\u001b[39m.\u001b[39mcompressed()  \n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mpoisson(torch\u001b[39m.\u001b[39;49mtensor(actual_fs))\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid Poisson rate, expected rate to be non-negative"
     ]
    }
   ],
   "source": [
    "from sbi.inference import SNRE_A\n",
    "\n",
    "inferer = SNRE_A(prior, show_progress_bars=True, device='cuda')\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "for i in range(0,rounds):\n",
    "    \n",
    "\n",
    "    theta, x = simulate_for_sbi(momment_sim, proposal, num_sim)\n",
    "    liklihood_estimator = inferer.append_simulations(theta, x).train(training_batch_size=50)\n",
    "    posterior = inferer.build_posterior(density_estimator=liklihood_estimator, sample_with = \"vi\", \n",
    "                                        vi_method=\"fKL\", vi_parameters=vi_parameters)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_x[0]).train(max_num_iters=40, quality_control=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RestrictionEstimator.__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msbi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m RestrictionEstimator\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m restriction_estimator \u001b[39m=\u001b[39m RestrictionEstimator(prior\u001b[39m=\u001b[39;49mprior, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m proposals \u001b[39m=\u001b[39m [prior]\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,rounds):\n",
      "\u001b[0;31mTypeError\u001b[0m: RestrictionEstimator.__init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "from sbi.utils import RestrictionEstimator\n",
    "\n",
    "restriction_estimator = RestrictionEstimator(prior=prior, device='cuda')\n",
    "proposals = [prior]\n",
    "\n",
    "for i in range(0,rounds):\n",
    "    theta, x = simulate_for_sbi(momment_sim, proposals[-1], 500)\n",
    "    restriction_estimator.append_simulations(theta, x)\n",
    "    if (i < rounds - 1):  # training not needed in last round because classifier will not be used anymore.\n",
    "        classifier = restriction_estimator.train()\n",
    "    proposals.append(restriction_estimator.restrict_prior())\n",
    "\n",
    "all_theta, all_x, _ = restriction_estimator.get_simulations()\n",
    "\n",
    "inferer = SNRE_A(prior, show_progress_bars=True, device='cuda')\n",
    "density_estimator = inferer.append_simulations(all_theta, all_x).train()\n",
    "posterior = inferer.build_posterior(density_estimator, sample_with = \"vi\",\n",
    "                                    vi_method=\"fKL\", vi_parameters=vi_parameters)\n",
    "inferer.set_default_x(true_x[0]).train(max_num_iters=40, quality_control=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [50, 50] doesn't match the broadcast shape [50, 50, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m theta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(thetas, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(xs)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m liklihood_estimator \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39;49mappend_simulations(theta, x)\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m a_post \u001b[39m=\u001b[39m inferer\u001b[39m.\u001b[39mbuild_posterior(density_estimator\u001b[39m=\u001b[39mliklihood_estimator, sample_with \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvi\u001b[39m\u001b[39m\"\u001b[39m, vi_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfKL\u001b[39m\u001b[39m\"\u001b[39m, vi_parameters\u001b[39m=\u001b[39mvi_parameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/moments/posteror_ensamble2.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m posteriors\u001b[39m.\u001b[39mappend(a_post)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/snle/snle_base.py:229\u001b[0m, in \u001b[0;36mLikelihoodEstimator.train\u001b[0;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, resume_training, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m theta_batch, x_batch \u001b[39m=\u001b[39m (\n\u001b[1;32m    225\u001b[0m     batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device),\n\u001b[1;32m    226\u001b[0m     batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device),\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[39m# Evaluate on x with theta as context.\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m train_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss(theta\u001b[39m=\u001b[39;49mtheta_batch, x\u001b[39m=\u001b[39;49mx_batch)\n\u001b[1;32m    230\u001b[0m train_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(train_losses)\n\u001b[1;32m    231\u001b[0m train_log_probs_sum \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m train_losses\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/sbi/inference/snle/snle_base.py:396\u001b[0m, in \u001b[0;36mLikelihoodEstimator._loss\u001b[0;34m(self, theta, x)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_loss\u001b[39m(\u001b[39mself\u001b[39m, theta: Tensor, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    391\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Return loss for SNLE, which is the likelihood of $-\\log q(x_i | \\theta_i)$.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39m        Negative log prob.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_neural_net\u001b[39m.\u001b[39;49mlog_prob(x, context\u001b[39m=\u001b[39;49mtheta)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/nflows/distributions/base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m context\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of input items must be equal to number of context items.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_prob(inputs, context)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/nflows/flows/base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_prob\u001b[39m(\u001b[39mself\u001b[39m, inputs, context):\n\u001b[1;32m     38\u001b[0m     embedded_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 39\u001b[0m     noise, logabsdet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(inputs, context\u001b[39m=\u001b[39;49membedded_context)\n\u001b[1;32m     40\u001b[0m     log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution\u001b[39m.\u001b[39mlog_prob(noise, context\u001b[39m=\u001b[39membedded_context)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m log_prob \u001b[39m+\u001b[39m logabsdet\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/nflows/transforms/base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     funcs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transforms\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cascade(inputs, funcs, context)\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[39m=\u001b[39m func(outputs, context)\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/nflows/transforms/autoregressive.py:38\u001b[0m, in \u001b[0;36mAutoregressiveTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 38\u001b[0m     autoregressive_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautoregressive_net(inputs, context)\n\u001b[1;32m     39\u001b[0m     outputs, logabsdet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elementwise_forward(inputs, autoregressive_params)\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/sda/home/ludeep/Desktop/PopGen/FinBank/moments_sfs/momentssfs/lib/python3.10/site-packages/nflows/transforms/made.py:277\u001b[0m, in \u001b[0;36mMADE.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m    275\u001b[0m temps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_layer(inputs)\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     temps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_layer(context))\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_residual_blocks:\n\u001b[1;32m    279\u001b[0m     temps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(temps)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [50, 50] doesn't match the broadcast shape [50, 50, 50]"
     ]
    }
   ],
   "source": [
    "posteriors = []\n",
    "thetas= []\n",
    "xs = []\n",
    "for i in range(0,rounds):\n",
    "    \n",
    "    if i == 0:\n",
    "        for j in range(0,num_sim): \n",
    "            a_theta = prior.sample((1,)).detach().cpu().numpy()\n",
    "            x = momment_sim(a_theta)\n",
    "            xs.append(x)\n",
    "            thetas.append(a_theta)\n",
    "        theta = torch.tensor(thetas, dtype=torch.float32)\n",
    "        x = torch.stack(xs).type(torch.float32)\n",
    "        liklihood_estimator = inferer.append_simulations(theta, x).train()\n",
    "        a_post = inferer.build_posterior(density_estimator=liklihood_estimator, sample_with = \"vi\", vi_method=\"fKL\", vi_parameters=vi_parameters)\n",
    "        posteriors.append(a_post)\n",
    "        proposal = a_post.set_default_x(true_x).train(max_num_iters=40, quality_control=False )\n",
    "    else:\n",
    "        for j in num_sim: \n",
    "            a_theta = prior.sample((1,)).detach().cpu().numpy()\n",
    "            x = momment_sim(a_theta)\n",
    "            xs.append(x)\n",
    "            thetas.append(a_theta)\n",
    "        theta = torch.tensor(thetas, dtype=torch.float32)\n",
    "        x = torch.stack(xs).type(torch.float32)\n",
    "        #theta, x = simulate_for_sbi(simulator, proposal, num_sim)\n",
    "        liklihood_estimator = inferer.append_simulations(theta, x, proposal=proposal).train(training_batch_size=20)\n",
    "        posteriors.append(a_post)\n",
    "        proposal = a_post.set_default_x(true_x).train(max_num_iters=40, quality_control=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debdc18397234941bfbd0507eb9a32d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 83 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d9a0954d914b54b3e9d467ff20c83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a61fcfec0242539738db2b282a2503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 33 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66a2ba17bd54cb8891b90c2f37d987d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 rounds: first round simulates from the prior, second round simulates parameter set\n",
    "# that were sampled from the obtained posterior.\n",
    "num_rounds = 2\n",
    "# The specific observation we want to focus the inference on.\n",
    "x_o = torch.zeros(\n",
    "    3,\n",
    ")\n",
    "\n",
    "num_dim = 3\n",
    "prior = utils.BoxUniform(low=-2 * torch.ones(num_dim), high=2 * torch.ones(num_dim))\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "\n",
    "def linear_gaussian(theta):\n",
    "    return theta + 1.0 + torch.randn_like(theta) * 0.1\n",
    "\n",
    "simulator, prior = prepare_for_sbi(linear_gaussian, prior)\n",
    "inference = SNPE(prior=prior)\n",
    "\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulator, proposal, num_simulations=500)\n",
    "\n",
    "    # In `SNLE` and `SNRE`, you should not pass the `proposal` to `.append_simulations()`\n",
    "    density_estimator = inference.append_simulations(\n",
    "        theta, x, proposal=proposal\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator, sample_with = \"vi\", vi_method=\"fKL\")\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(x_o).train(max_num_iters=40, quality_control=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('SFS': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c011ed9bb21179cd579adf84b3829b40600ff69d12d61fe328e5e2fbe10069c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
