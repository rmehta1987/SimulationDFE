{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/PopGen/SimulationSFS/SFS/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/rahul/PopGen/SimulationSFS/SFS/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/rahul/PopGen/SimulationSFS/SFS/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi, SNLE, MNLE, SNRE, SNRE_A\n",
    "from sbi.utils.posterior_ensemble import NeuralPosteriorEnsemble\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.utils import MultipleIndependent\n",
    "from sbi.neural_nets.embedding_nets import PermutationInvariantEmbedding, FCEmbedding\n",
    "from sbi.utils.user_input_checks import process_prior, process_simulator\n",
    "from sbi.utils import get_density_thresholder, RestrictedPrior\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "import numpy as np\n",
    "import moments\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import atexit\n",
    "import torch.nn.functional as F\n",
    "import subprocess\n",
    "import sparselinear as sl\n",
    "from sortedcontainers import SortedDict\n",
    "from scipy.spatial import KDTree\n",
    "import os\n",
    "import re\n",
    "from monarch_linear import MonarchLinear\n",
    "import pdb\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR) # See: https://github.com/matplotlib/matplotlib/issues/14523\n",
    "from collections import defaultdict\n",
    "from sbi.analysis import pairplot\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=360388\n",
    "the_device='cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = int(sample_size*2*(0.1/100))# cut_off frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryNet(nn.Module):\n",
    "    def __init__(self, sample_size, block_sizes, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.sample_size = sample_size # For monarch this needs to be divisible by the block size\n",
    "        self.block_size = block_sizes\n",
    "        self.linear4 = MonarchLinear(sample_size, int(sample_size / 10), nblocks=self.block_size[0]) # 11171\n",
    "        self.linear5 = MonarchLinear(int(self.sample_size / 10), int(self.sample_size / 10) , nblocks=self.block_size[1]) # 11171\n",
    "        self.linear6 = MonarchLinear(int(self.sample_size / 10), int(self.sample_size / 10), nblocks=self.block_size[2]) # 11171\n",
    "\n",
    "        self.model = nn.Sequential(self.linear4, nn.Dropout(dropout_rate), nn.GELU(),\n",
    "                                   self.linear5, nn.Dropout(dropout_rate), nn.GELU(),\n",
    "                                   self.linear6) \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_datafrom_hdf5(path_to_sim_file: str):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        path_to_sim_file (str): _description_\n",
    "    \"\"\"    \n",
    "    #TODO probably will be better to use https://github.com/quantopian/warp_prism for faster look-up tables\n",
    "    global loaded_file \n",
    "    global loaded_file_keys\n",
    "    global loaded_tree\n",
    "    import h5py\n",
    "    loaded_file = h5py.File(path_to_sim_file, 'r')\n",
    "    loaded_file_keys = list(loaded_file.keys())\n",
    "    loaded_tree = KDTree(np.asarray(loaded_file_keys)[:,None]) # needs to have a column dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregated_generate_sim_data(prior: float) -> torch.float32:\n",
    "\n",
    "    data = np.zeros((sample_size*2-1))\n",
    "    theprior = prior[:-1] # last dim is misidentification\n",
    "    gammas = 10**(theprior.cpu().numpy().squeeze())\n",
    "\n",
    "    scaling_theta=prior[-1].cpu().numpy()\n",
    "    for a_prior in gammas:\n",
    "        _, idx = loaded_tree.query(a_prior, k=(1,)) # the k sets number of neighbors, while we only want 1, we need to make sure it returns an array that can be indexed\n",
    "        fs = loaded_file[loaded_file_keys[idx[0]]][:]\n",
    "        fs = fs*(10**scaling_theta) # scale to gwas theta rate\n",
    "        fs = (fs[:sample_size*2-1])\n",
    "        data += fs\n",
    "    data = data /(theprior.shape[0]-1)\n",
    "    data = data.astype(int)\n",
    "    return torch.log(torch.nn.functional.relu(torch.tensor(data)+1).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_true_data(a_path: str, type: int) -> torch.float32:\n",
    "    \"\"\"Loads a true SFS, note that the sample size must be consistent with the passed parameters\n",
    "\n",
    "    Args:\n",
    "        path (str): Where the true-SFS is located, must be a numpy array\n",
    "        type (int): is data stored in numpy pickle (0) or torch pickle (1)\n",
    "\n",
    "    Returns:\n",
    "        Returns the SFS of the true data-set\n",
    "    \"\"\"\n",
    "    if type == 0:\n",
    "        sfs = np.load(a_path)\n",
    "        sfs = torch.tensor(sfs, device=the_device).type(torch.float32)\n",
    "    else:\n",
    "        sfs = torch.load(a_path)\n",
    "        sfs.to(the_device)\n",
    "    assert sfs.shape[0] == sample_size*2-1, \"Sample Size must be the same dimensions as the Site Frequency Spectrum, SFS shape: {} and sample shape (2*N-1): {}\".format(sfs.shape[0], sample_size*2-1)\n",
    "\n",
    "    return sfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sim_datafrom_hdf5('chr10_sim_genome_wide_mut_sfs_gwas.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "udist = torch.distributions.uniform.Uniform(-6.0*torch.ones(50),4.0*torch.ones(50))\n",
    "uniform_samples = udist.sample((1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_posterior=torch.load('nfe_restriction_classifier_gwas_embedding_final.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_x = (load_true_data('emperical_standiing_height_gwas.npy', 0)[:-1]).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of true data: 720774\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of true data: {}\".format(true_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal = last_posterior.restrict_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_samples = proposal.sample((100,), oversampling_factor=1024)[:,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.7436, -3.3859, -3.6393, -3.7399, -3.7507, -3.6475, -3.7763, -3.8871,\n",
       "        -3.4344, -3.3926, -3.6163, -3.5240, -3.2402, -3.5826, -3.7637, -3.5524,\n",
       "        -3.5065, -3.4306, -3.6372, -3.2210, -3.5641, -3.2965, -3.3962, -3.4016,\n",
       "        -3.8603, -3.5941, -3.8820, -3.6374, -3.4875, -3.7401, -3.6473, -3.6426,\n",
       "        -3.5212, -3.1718, -3.6219, -3.8104, -3.6296, -3.5811, -3.2859, -3.8620,\n",
       "        -3.6544, -3.3300, -3.3908, -3.9823, -3.4256, -3.4680, -3.7673, -3.5709,\n",
       "        -3.3899, -3.5671, -3.5878, -3.3960, -3.1534, -3.3696, -3.4476, -3.7206,\n",
       "        -3.6791, -3.5400, -3.8363, -3.4467], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(obs_samples,dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.4785, -0.6062, -2.4141, -5.4499, -1.3839, -1.0286, -1.7420, -2.1192,\n",
       "        -6.6727, -6.2917, -2.2872, -2.0298, -0.2443, -5.7555, -6.4988, -4.5858,\n",
       "        -6.7222, -5.8016, -6.9031, -0.8002, -1.5555, -4.2450, -0.5596, -0.3094,\n",
       "        -2.8221, -1.8723, -5.1864, -1.7985, -5.7647, -6.6136, -1.8481, -3.0345,\n",
       "        -0.1278, -2.9326, -0.2739, -6.5146, -2.7501, -2.5380, -4.7748, -2.1977,\n",
       "        -3.0237, -4.5051, -1.7391, -6.0884, -2.3353, -5.0147, -6.7540, -5.1095,\n",
       "        -5.3367, -1.1296, -2.7863, -1.3614, -3.3874, -3.3689, -1.2930, -3.8117,\n",
       "        -3.8608, -0.3258, -1.6060], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_samples[0,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = loaded_tree.query(obs_samples[0,1].cpu().numpy(), k=(1,)) # the k sets number of neighbors, while we only want 1, we need to make sure it returns an array that can be indexed\n",
    "fs = loaded_file[loaded_file_keys[idx[0]]][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060.08"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs[min_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sampled selection coefficients: torch.Size([100, 60])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of sampled selection coefficients: {}\".format(obs_samples.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for obs_sample in tqdm(obs_samples):\n",
    "    fs = aggregated_generate_sim_data(obs_sample)\n",
    "    predicted_fs.append(fs.unsqueeze(0).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frequency spectrum containing all bins (200, 720775)\n"
     ]
    }
   ],
   "source": [
    "new_predicted_fs = np.asarray(predicted_fs).squeeze(1)\n",
    "print(\"Shape of frequency spectrum containing all bins {}\".format(new_predicted_fs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.058207, 12.203549, 11.606325, ...,  0.      ,  0.      ,\n",
       "        0.      ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predicted_fs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of predicted SFS: [1.302827  1.3019902 1.2986102 1.297986  1.297057  1.2960618 1.2949531\n",
      " 1.2939458 1.2934831 1.2928555]\n",
      "tensor([619., 674., 718., 692., 804., 772., 847., 868., 905., 903.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "mean_predicted = np.mean(new_predicted_fs[:],axis=0)\n",
    "print(f\"Mean of predicted SFS: {mean_predicted[min_freq:min_freq+10]}\")\n",
    "print(true_x[0, min_freq:min_freq+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "for i in range(1, 25):\n",
    "    ax = fig.add_subplot(5, 5, i)\n",
    "    sns.histplot(np.log10(new_predicted_fs[:,i-1]))\n",
    "    plt.axvline(x=np.mean(np.log10(new_predicted_fs[:,i-1])), color='m', label=\"mean\")\n",
    "    plt.axvline(x=np.median(np.log10(new_predicted_fs[:,i-1])), color='k', label=\"median\")\n",
    "    ax.axline((np.log10(true_x[i-1]), 1), (np.log10(true_x[i-1]),100), marker='+', c='r', label=\"Emperical SFS\")\n",
    "    plt.title(\"Emperical SFS: 10^{:.3f} at bin: {}\".format(np.log10(true_x[i-1]),i))\n",
    "fig.legend([\"mean\", \"median\", \"Emperical SFS\"], loc=\"lower center\", ncol=4)\n",
    "plt.savefig('ppc_check_hist_mis_36_coefficients_round2_blur_2_hs.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "for i in range(1, 25):\n",
    "    ax = fig.add_subplot(5, 5, i)\n",
    "    sns.histplot(np.log10(new_predicted_fs2[:,i-1]))\n",
    "    plt.axvline(x=np.mean(np.log10(new_predicted_fs2[:,i-1])), color='m', label=\"mean\")\n",
    "    plt.axvline(x=np.median(np.log10(new_predicted_fs2[:,i-1])), color='k', label=\"median\")\n",
    "    ax.axline((np.log10(true_x[i-1]), 1), (np.log10(true_x[i-1]),100), marker='+', c='r', label=\"Emperical SFS\")\n",
    "    plt.title(\"Emperical SFS: 10^{:.3f} at bin: {}\".format(np.log10(true_x[i-1]),i))\n",
    "fig.legend([\"mean\", \"median\", \"Emperical SFS\"], loc=\"lower center\", ncol=4)\n",
    "plt.savefig('ppc_check_hist_lof_36_coefficients_round2_blur_2_s.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 111708])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to create a normalized batch tensor of the predicted frequency spectrum\n",
    "temp = torch.tensor(predicted_fs)\n",
    "temp = temp.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_predicted_fs = temp/temp.sum(dim=1).view(temp.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp[0,:10])\n",
    "print(temp.sum(dim=1)[0])\n",
    "print(norm_predicted_fs[0,:10])\n",
    "# Test to create a normalized batch tensor of the predicted frequency spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of frequency bins on x-axis for plotting 200\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(0,mean_predicted[:200].shape[0])\n",
    "print(\"Shape of frequency bins on x-axis for plotting {}\".format(x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=x,y=np.log10(mean_predicted[:200]+1), label=\"Predicted\")\n",
    "sns.scatterplot(x=x,y=np.log10(true_x.cpu().numpy()[0,:200]+1), label=\"Emperical\")\n",
    "plt.title(\"Mean of posterior predicted SFS vs True SFS\")\n",
    "plt.ylabel(\"Log Scaled Allele Frequency\")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "#fig.legend([\"Predicted\", \"Emperical\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('ppc_scatter_lof_nfe_round_3.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=x,y=np.log10(mean_predicted2+1), label=\"Predicted\")\n",
    "sns.scatterplot(x=x,y=np.log10(true_x+1), label=\"Emperical\")\n",
    "plt.title(\"Mean of posterior predicted SFS vs True SFS\")\n",
    "plt.ylabel(\"Log Scaled Allele Frequency\")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "#fig.legend([\"Predicted\", \"Emperical\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('ppc_scatter_mis_36_coefficients_round1.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 60])\n",
      "tensor([-3.6042, -3.4862, -3.4878, -3.5170, -3.5543, -3.5059, -3.5199, -3.5383,\n",
      "        -3.7101, -3.5415, -3.4439, -3.6128, -3.5215, -3.5429, -3.6729, -3.5535,\n",
      "        -3.6120, -3.4460, -3.5710, -3.5401, -3.6356, -3.5594, -3.4464, -3.5448,\n",
      "        -3.5348, -3.4697, -3.6557, -3.5755, -3.4994, -3.5083, -3.4280, -3.5558,\n",
      "        -3.6247, -3.5190, -3.5291, -3.4545, -3.6503, -3.4407, -3.5591, -3.5766,\n",
      "        -3.5873, -3.5375, -3.4949, -3.5990, -3.5165, -3.5074, -3.5106, -3.5948,\n",
      "        -3.5323, -3.5583, -3.5479, -3.5093, -3.6229, -3.5799, -3.5042, -3.5697,\n",
      "        -3.4173, -3.6066, -3.6029, -3.5630], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(obs_samples.shape)\n",
    "print(obs_samples.mean(dim=0))\n",
    "obs_samples2 = obs_samples.reshape(-1)\n",
    "\n",
    "samps = obs_samples2.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samps =last_posterior._prior.sample((2000,)).view(-1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.kdeplot(samps, label=\"DFE\", c='r')\n",
    "sns.kdeplot(prior_samps, label=\"Initial Proposal\", c='g')\n",
    "plt.title(\"Kernel Density Estimation Inferred Scaled Selection\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(\"Log of Absolute Scaled Selection Coefficient\")\n",
    "fig.legend([\"DFE\", \"Initial Proposal\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('ppc_nfe_selectiion_round3.png')\n",
    "plt.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe2= samps.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 <= |s| < 1e-05: 0.0000000\n",
      "1e-05 <= |s| < 0.0001: 0.0000000\n",
      "0.0001 <= |s| < 0.001: 0.0000000\n",
      "0.001 <= |s| < 0.01: 0.3749375\n",
      "0.01 <= |s| < 0.1: 0.0915938\n",
      "0.1 <= |s| < 1: 0.0851250\n",
      "1 <= |s| < 10000.0: 0.4483437\n",
      "|s| > 10000.0: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "bins = [-6, -5, -4, -3, -2, -1, 0, 4.0]\n",
    "for s0, s1 in zip(bins[:-1], bins[1:]):\n",
    "    the_dat=np.extract((s0 <= dfe2) & (dfe2 < s1), dfe2)\n",
    "    prop = the_dat.shape[0]/obs_samples2.shape[0]\n",
    "    print(f\"{10**s0} <= |s| < {10**s1}: {prop:.7f}\")\n",
    "    if s1 == bins[-1]:\n",
    "        the_dat=np.extract(dfe2 > s1, dfe2)\n",
    "        prop = the_dat.shape[0]/500000.0\n",
    "        print(f\"|s| > {10**s1}: {prop:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss between true and predicted in poisson log-liklihood\n",
    "loss = -1*torch.nn.functional.poisson_nll_loss(torch.log(torch.tensor(mean_predicted2+1)), torch.log(torch.tensor(true_x+1)),log_input=True, full=False, reduction='sum' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_predicted = torch.log(torch.tensor(new_predicted_fs).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_target = torch.log(torch.tensor(true_x+1).repeat(log_predicted.shape[0],1).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = -1*torch.nn.functional.poisson_nll_loss(log_predicted, log_target, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson log-liklihood loss -4795.529159783006 vs moments log-liklihood loss for lof -237.79096099886482\n"
     ]
    }
   ],
   "source": [
    "print(\"poisson log-liklihood loss {} vs moments log-liklihood loss for lof {}\".format(loss, moments_loss_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson log-liklihood loss over batch -47.59079092120809 vs moments log-liklihood loss for lof -237.79096099886482\n"
     ]
    }
   ],
   "source": [
    "print(\"poisson log-liklihood loss over batch {} vs moments log-liklihood loss for lof {}\".format(loss2, moments_loss_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = (mean_predicted - true_x)/np.sqrt(mean_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=x,y=resid, label=\"Residual\")\n",
    "plt.title(\"Poisson Residuals\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "#fig.legend([\"Predicted\", \"Emperical\"], loc=\"lower center\", ncol=2)\n",
    "plt.savefig('resid_lof_32_coefficients_round10.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.5309, 5.0752, 4.4188, 4.0943, 3.6376, 3.1781, 3.1781, 2.6391, 2.5649,\n",
       "         2.7726, 2.7081, 2.7081, 2.7081, 2.7726, 2.3026, 1.0986, 2.3026, 2.3979,\n",
       "         1.6094, 1.9459, 1.3863, 1.6094, 1.3863, 1.9459, 1.9459, 1.7918, 1.3863,\n",
       "         1.6094, 1.0986, 1.0986, 1.6094, 1.7918, 2.0794, 1.6094, 1.0986, 1.6094,\n",
       "         2.0794, 0.6931, 1.0986, 1.3863, 1.3863, 0.6931, 1.0986, 0.6931, 0.0000,\n",
       "         1.0986, 0.6931, 1.0986, 0.6931, 0.6931, 0.0000, 1.0986, 1.0986, 0.6931,\n",
       "         1.0986, 1.0986, 0.6931, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6931,\n",
       "         0.0000, 0.6931, 0.6931, 0.6931, 0.0000, 0.0000, 0.6931, 0.6931, 0.0000,\n",
       "         0.6931, 0.6931, 1.3863, 0.6931, 0.6931, 0.0000, 0.6931, 0.6931, 0.0000,\n",
       "         0.0000, 0.0000, 1.3863, 0.6931, 0.6931, 0.6931, 0.0000, 0.6931, 0.6931,\n",
       "         1.0986, 0.0000, 0.6931, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0986,\n",
       "         0.0000, 0.0000, 0.0000, 0.6931, 0.0000, 0.6931, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6931,\n",
       "         0.0000, 0.6931, 0.6931, 0.0000, 0.0000, 0.6931, 0.6931, 0.6931, 0.6931,\n",
       "         0.0000, 0.0000, 0.6931, 0.0000, 0.0000, 0.0000, 0.0000, 0.6931, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 1.0986, 0.0000, 0.0000, 0.6931, 0.6931, 1.0986, 0.6931, 0.6931,\n",
       "         0.0000, 0.0000, 0.0000, 0.6931, 0.0000, 0.6931, 0.6931, 1.0986, 0.0000,\n",
       "         0.0000, 0.0000, 1.0986, 0.0000, 0.6931, 0.0000, 0.6931]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c011ed9bb21179cd579adf84b3829b40600ff69d12d61fe328e5e2fbe10069c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
